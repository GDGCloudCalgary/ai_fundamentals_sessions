{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from PIL import Image as pil_image\n",
    "from tensorflow.keras.preprocessing.image import save_img\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import vgg16\n",
    "from tensorflow.keras import backend \n",
    "from tensorflow.keras import backend  as K\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"utility function to normalize a tensor.\n",
    "    # Arguments\n",
    "        x: An input tensor.\n",
    "    # Returns\n",
    "        The normalized input tensor.\n",
    "    \"\"\"\n",
    "    return x / (backend.sqrt(backend.mean(K.square(x))) + backend.epsilon())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deprocess_image(x):\n",
    "    \"\"\"utility function to convert a float array into a valid uint8 image.\n",
    "    # Arguments\n",
    "        x: A numpy-array representing the generated image.\n",
    "    # Returns\n",
    "        A processed numpy-array, which could be used in e.g. imshow.\n",
    "    \"\"\"\n",
    "    # normalize tensor: center on 0., ensure std is 0.25\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + backend.epsilon())\n",
    "    x *= 0.25\n",
    "\n",
    "    # clip to [0, 1]\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "\n",
    "    # convert to RGB array\n",
    "    x *= 255\n",
    "    if backend.image_data_format() == 'channels_first':\n",
    "        x = x.transpose((1, 2, 0))\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(x, former):\n",
    "    \"\"\"utility function to convert a valid uint8 image back into a float array.\n",
    "       Reverses `deprocess_image`.\n",
    "    # Arguments\n",
    "        x: A numpy-array, which could be used in e.g. imshow.\n",
    "        former: The former numpy-array.\n",
    "                Need to determine the former mean and variance.\n",
    "    # Returns\n",
    "        A processed numpy-array representing the generated image.\n",
    "    \"\"\"\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x = x.transpose((2, 0, 1))\n",
    "    return (x / 255 - 0.5) * 4 * former.std() + former.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_layer(model,\n",
    "                    layer_name,\n",
    "                    step=1.,\n",
    "                    epochs=15,\n",
    "                    upscaling_steps=9,\n",
    "                    upscaling_factor=1.2,\n",
    "                    output_dim=(412, 412),\n",
    "                    filter_range=(0, None)):\n",
    "    \"\"\"Visualizes the most relevant filters of one conv-layer in a certain model.\n",
    "    # Arguments\n",
    "        model: The model containing layer_name.\n",
    "        layer_name: The name of the layer to be visualized.\n",
    "                    Has to be a part of model.\n",
    "        step: step size for gradient ascent.\n",
    "        epochs: Number of iterations for gradient ascent.\n",
    "        upscaling_steps: Number of upscaling steps.\n",
    "                         Starting image is in this case (80, 80).\n",
    "        upscaling_factor: Factor to which to slowly upgrade\n",
    "                          the image towards output_dim.\n",
    "        output_dim: [img_width, img_height] The output image dimensions.\n",
    "        filter_range: Tupel[lower, upper]\n",
    "                      Determines the to be computed filter numbers.\n",
    "                      If the second value is `None`,\n",
    "                      the last filter will be inferred as the upper boundary.\n",
    "    \"\"\"\n",
    "\n",
    "    def _generate_filter_image(input_img,\n",
    "                               layer_output,\n",
    "                               filter_index):\n",
    "        \"\"\"Generates image for one particular filter.\n",
    "        # Arguments\n",
    "            input_img: The input-image Tensor.\n",
    "            layer_output: The output-image Tensor.\n",
    "            filter_index: The to be processed filter number.\n",
    "                          Assumed to be valid.\n",
    "        #Returns\n",
    "            Either None if no image could be generated.\n",
    "            or a tuple of the image (array) itself and the last loss.\n",
    "        \"\"\"\n",
    "        s_time = time.time()\n",
    "\n",
    "        # we build a loss function that maximizes the activation\n",
    "        # of the nth filter of the layer considered\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            loss = K.mean(layer_output[:, filter_index, :, :])\n",
    "        else:\n",
    "            loss = K.mean(layer_output[:, :, :, filter_index])\n",
    "\n",
    "        # we compute the gradient of the input picture wrt this loss\n",
    "        grads = K.gradients(loss, input_img)[0]\n",
    "\n",
    "        # normalization trick: we normalize the gradient\n",
    "        grads = normalize(grads)\n",
    "\n",
    "        # this function returns the loss and grads given the input picture\n",
    "        iterate = K.function([input_img], [loss, grads])\n",
    "\n",
    "        # we start from a gray image with some random noise\n",
    "        intermediate_dim = tuple(\n",
    "            int(x / (upscaling_factor ** upscaling_steps)) for x in output_dim)\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            input_img_data = np.random.random(\n",
    "                (1, 3, intermediate_dim[0], intermediate_dim[1]))\n",
    "        else:\n",
    "            input_img_data = np.random.random(\n",
    "                (1, intermediate_dim[0], intermediate_dim[1], 3))\n",
    "        input_img_data = (input_img_data - 0.5) * 20 + 128\n",
    "\n",
    "        # Slowly upscaling towards the original size prevents\n",
    "        # a dominating high-frequency of the to visualized structure\n",
    "        # as it would occur if we directly compute the 412d-image.\n",
    "        # Behaves as a better starting point for each following dimension\n",
    "        # and therefore avoids poor local minima\n",
    "        for up in reversed(range(upscaling_steps)):\n",
    "            # we run gradient ascent for e.g. 20 steps\n",
    "            for _ in range(epochs):\n",
    "                loss_value, grads_value = iterate([input_img_data])\n",
    "                input_img_data += grads_value * step\n",
    "\n",
    "                # some filters get stuck to 0, we can skip them\n",
    "                if loss_value <= K.epsilon():\n",
    "                    return None\n",
    "\n",
    "            # Calculate upscaled dimension\n",
    "            intermediate_dim = tuple(\n",
    "                int(x / (upscaling_factor ** up)) for x in output_dim)\n",
    "            # Upscale\n",
    "            img = deprocess_image(input_img_data[0])\n",
    "            img = np.array(pil_image.fromarray(img).resize(intermediate_dim,\n",
    "                                                           pil_image.BICUBIC))\n",
    "            input_img_data = np.expand_dims(\n",
    "                process_image(img, input_img_data[0]), 0)\n",
    "\n",
    "        # decode the resulting input image\n",
    "        img = deprocess_image(input_img_data[0])\n",
    "        e_time = time.time()\n",
    "        print('Costs of filter {:3}: {:5.0f} ( {:4.2f}s )'.format(filter_index,\n",
    "                                                                  loss_value,\n",
    "                                                                  e_time - s_time))\n",
    "        return img, loss_value\n",
    "\n",
    "    def _draw_filters(filters, n=None):\n",
    "        \"\"\"Draw the best filters in a nxn grid.\n",
    "        # Arguments\n",
    "            filters: A List of generated images and their corresponding losses\n",
    "                     for each processed filter.\n",
    "            n: dimension of the grid.\n",
    "               If none, the largest possible square will be used\n",
    "        \"\"\"\n",
    "        if n is None:\n",
    "            n = int(np.floor(np.sqrt(len(filters))))\n",
    "\n",
    "        # the filters that have the highest loss are assumed to be better-looking.\n",
    "        # we will only keep the top n*n filters.\n",
    "        filters.sort(key=lambda x: x[1], reverse=True)\n",
    "        filters = filters[:n * n]\n",
    "\n",
    "        # build a black picture with enough space for\n",
    "        # e.g. our 8 x 8 filters of size 412 x 412, with a 5px margin in between\n",
    "        MARGIN = 5\n",
    "        width = n * output_dim[0] + (n - 1) * MARGIN\n",
    "        height = n * output_dim[1] + (n - 1) * MARGIN\n",
    "        stitched_filters = np.zeros((width, height, 3), dtype='uint8')\n",
    "\n",
    "        # fill the picture with our saved filters\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                img, _ = filters[i * n + j]\n",
    "                width_margin = (output_dim[0] + MARGIN) * i\n",
    "                height_margin = (output_dim[1] + MARGIN) * j\n",
    "                stitched_filters[\n",
    "                    width_margin: width_margin + output_dim[0],\n",
    "                    height_margin: height_margin + output_dim[1], :] = img\n",
    "\n",
    "        # save the result to disk\n",
    "        save_img('vgg_{0:}_{1:}x{1:}.png'.format(layer_name, n), stitched_filters)\n",
    "\n",
    "    # this is the placeholder for the input images\n",
    "    assert len(model.inputs) == 1\n",
    "    input_img = model.inputs[0]\n",
    "\n",
    "    # get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
    "    layer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])\n",
    "\n",
    "    output_layer = layer_dict[layer_name]\n",
    "    assert isinstance(output_layer, layers.Conv2D)\n",
    "\n",
    "    # Compute to be processed filter range\n",
    "    filter_lower = filter_range[0]\n",
    "    filter_upper = (filter_range[1]\n",
    "                    if filter_range[1] is not None\n",
    "                    else len(output_layer.get_weights()[1]))\n",
    "    assert(filter_lower >= 0\n",
    "           and filter_upper <= len(output_layer.get_weights()[1])\n",
    "           and filter_upper > filter_lower)\n",
    "    print('Compute filters {:} to {:}'.format(filter_lower, filter_upper))\n",
    "\n",
    "    # iterate through each filter and generate its corresponding image\n",
    "    processed_filters = []\n",
    "    for f in range(filter_lower, filter_upper):\n",
    "        img_loss = _generate_filter_image(input_img, output_layer.output, f)\n",
    "\n",
    "        if img_loss is not None:\n",
    "            processed_filters.append(img_loss)\n",
    "\n",
    "    print('{} filter processed.'.format(len(processed_filters)))\n",
    "    # Finally draw and store the best filters to disk\n",
    "    _draw_filters(processed_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model loaded.\n",
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None, None, 3)]   0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Compute filters 0 to 512\n",
      "Costs of filter   0:   415 ( 46.04s )\n",
      "Costs of filter   1:  1156 ( 48.36s )\n",
      "Costs of filter   2:   412 ( 49.53s )\n",
      "Costs of filter   3:   511 ( 49.20s )\n",
      "Costs of filter   4:   603 ( 48.00s )\n",
      "Costs of filter   5:   491 ( 48.90s )\n",
      "Costs of filter   7:   977 ( 47.83s )\n",
      "Costs of filter   8:   867 ( 47.27s )\n",
      "Costs of filter   9:   467 ( 46.77s )\n",
      "Costs of filter  11:   782 ( 47.93s )\n",
      "Costs of filter  13:   346 ( 44.29s )\n",
      "Costs of filter  14:   709 ( 44.70s )\n",
      "Costs of filter  15:   520 ( 43.71s )\n",
      "Costs of filter  17:   841 ( 43.72s )\n",
      "Costs of filter  20:   520 ( 43.59s )\n",
      "Costs of filter  24:   452 ( 43.72s )\n",
      "Costs of filter  25:   550 ( 44.32s )\n",
      "Costs of filter  27:   901 ( 44.51s )\n",
      "Costs of filter  28:   525 ( 44.67s )\n",
      "Costs of filter  29:   536 ( 44.43s )\n",
      "Costs of filter  30:   565 ( 44.01s )\n",
      "Costs of filter  31:   400 ( 44.11s )\n",
      "Costs of filter  32:   389 ( 44.07s )\n",
      "Costs of filter  36:   862 ( 44.23s )\n",
      "Costs of filter  37:   791 ( 43.93s )\n",
      "Costs of filter  40:   857 ( 45.00s )\n",
      "Costs of filter  42:   866 ( 45.07s )\n",
      "Costs of filter  43:   419 ( 44.70s )\n",
      "Costs of filter  44:   605 ( 44.73s )\n",
      "Costs of filter  46:   974 ( 45.15s )\n",
      "Costs of filter  47:   687 ( 45.29s )\n",
      "Costs of filter  48:   678 ( 44.84s )\n",
      "Costs of filter  49:   810 ( 44.93s )\n",
      "Costs of filter  51:   478 ( 44.23s )\n",
      "Costs of filter  53:   681 ( 44.37s )\n",
      "Costs of filter  55:   405 ( 45.64s )\n",
      "Costs of filter  56:   773 ( 45.21s )\n",
      "Costs of filter  58:   350 ( 45.19s )\n",
      "Costs of filter  59:   865 ( 45.22s )\n",
      "Costs of filter  61:   918 ( 45.28s )\n",
      "Costs of filter  62:   635 ( 45.06s )\n",
      "Costs of filter  63:  1108 ( 45.17s )\n",
      "Costs of filter  64:  1274 ( 44.99s )\n",
      "Costs of filter  65:   231 ( 44.81s )\n",
      "Costs of filter  68:   842 ( 45.50s )\n",
      "Costs of filter  70:   586 ( 45.13s )\n",
      "Costs of filter  73:   687 ( 45.45s )\n",
      "Costs of filter  74:   485 ( 45.19s )\n",
      "Costs of filter  75:   308 ( 45.37s )\n",
      "Costs of filter  76:   846 ( 45.33s )\n",
      "Costs of filter  79:   772 ( 45.46s )\n",
      "Costs of filter  80:   432 ( 44.94s )\n",
      "Costs of filter  81:   398 ( 45.21s )\n",
      "Costs of filter  82:   648 ( 45.29s )\n",
      "Costs of filter  84:   531 ( 45.95s )\n",
      "Costs of filter  86:  1031 ( 46.61s )\n",
      "Costs of filter  87:   778 ( 46.00s )\n",
      "Costs of filter  88:   894 ( 46.40s )\n",
      "Costs of filter  91:   663 ( 45.69s )\n",
      "Costs of filter  92:   462 ( 45.78s )\n",
      "Costs of filter  93:   626 ( 45.62s )\n",
      "Costs of filter  97:   435 ( 46.08s )\n",
      "Costs of filter  99:   453 ( 45.27s )\n",
      "Costs of filter 101:   342 ( 45.93s )\n",
      "Costs of filter 103:   968 ( 46.09s )\n",
      "Costs of filter 110:   637 ( 46.89s )\n",
      "Costs of filter 112:   313 ( 46.78s )\n",
      "Costs of filter 113:   619 ( 45.43s )\n",
      "Costs of filter 114:   769 ( 45.98s )\n",
      "Costs of filter 119:   848 ( 46.39s )\n",
      "Costs of filter 121:   422 ( 46.45s )\n",
      "Costs of filter 123:   444 ( 45.89s )\n",
      "Costs of filter 124:   351 ( 46.62s )\n",
      "Costs of filter 126:   957 ( 47.62s )\n",
      "Costs of filter 127:   436 ( 50.04s )\n",
      "Costs of filter 128:   831 ( 48.34s )\n",
      "Costs of filter 129:   630 ( 48.33s )\n",
      "Costs of filter 131:   568 ( 48.86s )\n",
      "Costs of filter 132:   363 ( 47.34s )\n",
      "Costs of filter 133:   515 ( 46.52s )\n",
      "Costs of filter 135:   422 ( 46.85s )\n",
      "Costs of filter 136:   725 ( 47.06s )\n",
      "Costs of filter 137:   425 ( 47.31s )\n",
      "Costs of filter 138:  1384 ( 46.83s )\n",
      "Costs of filter 139:   404 ( 46.45s )\n",
      "Costs of filter 140:   503 ( 46.72s )\n",
      "Costs of filter 141:   586 ( 47.30s )\n",
      "Costs of filter 143:   834 ( 47.77s )\n",
      "Costs of filter 145:   491 ( 47.52s )\n",
      "Costs of filter 146:  1260 ( 51.81s )\n",
      "Costs of filter 149:   519 ( 50.96s )\n",
      "Costs of filter 150:   760 ( 51.02s )\n",
      "Costs of filter 151:   559 ( 49.37s )\n",
      "Costs of filter 152:   595 ( 47.65s )\n",
      "Costs of filter 153:   477 ( 46.52s )\n",
      "Costs of filter 154:   649 ( 48.66s )\n",
      "Costs of filter 155:   442 ( 49.31s )\n",
      "Costs of filter 157:   889 ( 48.87s )\n",
      "Costs of filter 158:   704 ( 51.28s )\n",
      "Costs of filter 161:   448 ( 49.77s )\n",
      "Costs of filter 162:   633 ( 47.38s )\n",
      "Costs of filter 165:   516 ( 47.75s )\n",
      "Costs of filter 166:   746 ( 47.86s )\n",
      "Costs of filter 167:   681 ( 47.49s )\n",
      "Costs of filter 168:   551 ( 50.34s )\n",
      "Costs of filter 170:   779 ( 49.31s )\n",
      "Costs of filter 171:   649 ( 50.14s )\n",
      "Costs of filter 174:   648 ( 52.60s )\n",
      "Costs of filter 175:   486 ( 47.67s )\n",
      "Costs of filter 177:   779 ( 47.21s )\n",
      "Costs of filter 180:   432 ( 47.86s )\n",
      "Costs of filter 181:   645 ( 48.91s )\n",
      "Costs of filter 182:  1143 ( 51.97s )\n",
      "Costs of filter 183:   456 ( 56.67s )\n",
      "Costs of filter 185:   613 ( 52.04s )\n",
      "Costs of filter 186:   538 ( 52.75s )\n",
      "Costs of filter 187:   945 ( 47.82s )\n",
      "Costs of filter 188:   545 ( 48.15s )\n",
      "Costs of filter 190:   456 ( 48.39s )\n",
      "Costs of filter 192:   320 ( 49.83s )\n",
      "Costs of filter 197:   541 ( 49.67s )\n",
      "Costs of filter 201:   462 ( 48.93s )\n",
      "Costs of filter 203:   527 ( 48.63s )\n",
      "Costs of filter 204:   424 ( 48.86s )\n",
      "Costs of filter 206:   532 ( 50.06s )\n",
      "Costs of filter 207:   363 ( 49.32s )\n",
      "Costs of filter 208:   977 ( 48.82s )\n",
      "Costs of filter 209:   748 ( 48.69s )\n",
      "Costs of filter 212:   384 ( 48.93s )\n",
      "Costs of filter 213:   805 ( 49.05s )\n",
      "Costs of filter 214:   548 ( 48.76s )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Costs of filter 218:   475 ( 48.46s )\n",
      "Costs of filter 219:   820 ( 48.29s )\n",
      "Costs of filter 220:   786 ( 53.49s )\n",
      "Costs of filter 221:   572 ( 52.71s )\n",
      "Costs of filter 223:   390 ( 52.01s )\n",
      "Costs of filter 225:   168 ( 52.98s )\n",
      "Costs of filter 227:   437 ( 52.94s )\n",
      "Costs of filter 233:   382 ( 52.15s )\n",
      "Costs of filter 235:   785 ( 52.07s )\n",
      "Costs of filter 236:   563 ( 52.50s )\n",
      "Costs of filter 237:   554 ( 53.04s )\n",
      "Costs of filter 238:   591 ( 53.75s )\n",
      "Costs of filter 240:   521 ( 54.47s )\n",
      "Costs of filter 241:   716 ( 54.86s )\n",
      "Costs of filter 243:   798 ( 58.43s )\n",
      "Costs of filter 245:  1000 ( 49.81s )\n",
      "Costs of filter 246:   386 ( 50.21s )\n",
      "Costs of filter 247:   527 ( 53.17s )\n",
      "Costs of filter 249:   586 ( 52.20s )\n",
      "Costs of filter 250:  1037 ( 51.11s )\n",
      "Costs of filter 251:   479 ( 51.91s )\n",
      "Costs of filter 255:   676 ( 49.37s )\n",
      "Costs of filter 256:   438 ( 49.88s )\n",
      "Costs of filter 257:   571 ( 49.93s )\n",
      "Costs of filter 258:   614 ( 50.10s )\n",
      "Costs of filter 259:   437 ( 52.23s )\n",
      "Costs of filter 262:   477 ( 51.11s )\n",
      "Costs of filter 263:   562 ( 51.21s )\n",
      "Costs of filter 264:   601 ( 58.10s )\n",
      "Costs of filter 267:   404 ( 92.54s )\n",
      "Costs of filter 268:   473 ( 65.28s )\n",
      "Costs of filter 269:   623 ( 68.10s )\n",
      "Costs of filter 270:  1379 ( 65.12s )\n",
      "Costs of filter 271:   598 ( 68.27s )\n",
      "Costs of filter 275:   555 ( 63.51s )\n",
      "Costs of filter 278:   627 ( 60.98s )\n",
      "Costs of filter 280:   237 ( 64.07s )\n",
      "Costs of filter 281:   574 ( 63.90s )\n",
      "Costs of filter 282:   479 ( 65.03s )\n",
      "Costs of filter 283:   655 ( 60.84s )\n",
      "Costs of filter 285:   647 ( 62.18s )\n",
      "Costs of filter 286:   991 ( 63.19s )\n",
      "Costs of filter 287:   469 ( 65.82s )\n",
      "Costs of filter 289:   471 ( 64.89s )\n",
      "Costs of filter 293:   463 ( 69.94s )\n",
      "Costs of filter 294:   690 ( 67.11s )\n",
      "Costs of filter 295:   813 ( 68.74s )\n",
      "Costs of filter 296:   430 ( 64.07s )\n",
      "Costs of filter 297:   655 ( 65.29s )\n",
      "Costs of filter 299:   434 ( 64.63s )\n",
      "Costs of filter 300:  1037 ( 64.97s )\n",
      "Costs of filter 301:   854 ( 70.74s )\n",
      "Costs of filter 302:   944 ( 73.11s )\n",
      "Costs of filter 303:   550 ( 68.88s )\n",
      "Costs of filter 305:   448 ( 66.59s )\n",
      "Costs of filter 306:   730 ( 69.67s )\n",
      "Costs of filter 308:   712 ( 71.37s )\n",
      "Costs of filter 309:  1302 ( 76.69s )\n",
      "Costs of filter 311:   472 ( 76.52s )\n",
      "Costs of filter 318:   486 ( 72.44s )\n",
      "Costs of filter 320:   624 ( 69.24s )\n",
      "Costs of filter 322:   727 ( 74.26s )\n",
      "Costs of filter 323:   576 ( 71.27s )\n",
      "Costs of filter 328:   742 ( 66.33s )\n",
      "Costs of filter 331:   540 ( 68.58s )\n",
      "Costs of filter 333:   410 ( 65.98s )\n",
      "Costs of filter 334:   788 ( 68.81s )\n",
      "Costs of filter 336:   520 ( 68.39s )\n",
      "Costs of filter 339:   649 ( 68.30s )\n",
      "Costs of filter 341:   386 ( 68.08s )\n",
      "Costs of filter 345:   449 ( 70.34s )\n",
      "Costs of filter 346:   910 ( 70.25s )\n",
      "Costs of filter 348:   760 ( 69.11s )\n",
      "Costs of filter 349:   529 ( 70.10s )\n",
      "Costs of filter 352:   599 ( 68.41s )\n",
      "Costs of filter 353:   670 ( 69.57s )\n",
      "Costs of filter 356:   828 ( 67.97s )\n",
      "Costs of filter 357:   492 ( 69.37s )\n",
      "Costs of filter 359:   624 ( 70.58s )\n",
      "Costs of filter 360:   364 ( 68.86s )\n",
      "Costs of filter 361:   517 ( 69.57s )\n",
      "Costs of filter 362:   616 ( 68.55s )\n",
      "Costs of filter 365:   798 ( 69.91s )\n",
      "Costs of filter 366:   389 ( 70.37s )\n",
      "Costs of filter 367:   716 ( 69.21s )\n",
      "Costs of filter 368:   902 ( 70.57s )\n",
      "Costs of filter 371:  1232 ( 69.71s )\n",
      "Costs of filter 374:   560 ( 68.02s )\n",
      "Costs of filter 375:   576 ( 70.28s )\n",
      "Costs of filter 376:   978 ( 71.20s )\n",
      "Costs of filter 377:   669 ( 70.10s )\n",
      "Costs of filter 378:   593 ( 70.95s )\n",
      "Costs of filter 380:   463 ( 69.48s )\n",
      "Costs of filter 381:   520 ( 70.56s )\n",
      "Costs of filter 383:   984 ( 71.57s )\n",
      "Costs of filter 387:   688 ( 71.47s )\n",
      "Costs of filter 389:   502 ( 72.21s )\n",
      "Costs of filter 392:   375 ( 71.75s )\n",
      "Costs of filter 393:   375 ( 72.06s )\n",
      "Costs of filter 394:   599 ( 72.41s )\n",
      "Costs of filter 397:   587 ( 71.58s )\n",
      "Costs of filter 399:   810 ( 74.80s )\n",
      "Costs of filter 402:   381 ( 72.73s )\n",
      "Costs of filter 405:   691 ( 74.04s )\n",
      "Costs of filter 410:   279 ( 72.01s )\n",
      "Costs of filter 412:   808 ( 71.15s )\n",
      "Costs of filter 414:   419 ( 71.69s )\n",
      "Costs of filter 415:   966 ( 72.36s )\n",
      "Costs of filter 416:   420 ( 70.17s )\n",
      "Costs of filter 417:   659 ( 70.95s )\n",
      "Costs of filter 418:   657 ( 72.23s )\n",
      "Costs of filter 421:   518 ( 71.91s )\n",
      "Costs of filter 422:   477 ( 70.40s )\n",
      "Costs of filter 423:   770 ( 71.79s )\n",
      "Costs of filter 424:   604 ( 73.74s )\n",
      "Costs of filter 427:   577 ( 71.61s )\n",
      "Costs of filter 428:   716 ( 71.67s )\n",
      "Costs of filter 430:   465 ( 72.69s )\n",
      "Costs of filter 433:   648 ( 71.81s )\n",
      "Costs of filter 435:   542 ( 72.89s )\n",
      "Costs of filter 436:   824 ( 72.45s )\n",
      "Costs of filter 437:   761 ( 75.35s )\n",
      "Costs of filter 438:   672 ( 73.55s )\n",
      "Costs of filter 439:   819 ( 73.20s )\n",
      "Costs of filter 442:   716 ( 74.37s )\n",
      "Costs of filter 444:   651 ( 74.02s )\n",
      "Costs of filter 445:   411 ( 73.97s )\n",
      "Costs of filter 446:   810 ( 75.36s )\n",
      "Costs of filter 448:   463 ( 74.93s )\n",
      "Costs of filter 449:   542 ( 74.70s )\n",
      "Costs of filter 452:   702 ( 74.99s )\n",
      "Costs of filter 453:   623 ( 75.36s )\n",
      "Costs of filter 455:   773 ( 75.72s )\n",
      "Costs of filter 457:   604 ( 74.73s )\n",
      "Costs of filter 458:   709 ( 75.07s )\n",
      "Costs of filter 460:   729 ( 74.43s )\n",
      "Costs of filter 461:   431 ( 78.24s )\n",
      "Costs of filter 462:   472 ( 76.59s )\n",
      "Costs of filter 464:   439 ( 75.32s )\n",
      "Costs of filter 465:   477 ( 75.22s )\n",
      "Costs of filter 467:   460 ( 76.81s )\n",
      "Costs of filter 470:   435 ( 77.00s )\n",
      "Costs of filter 473:   722 ( 76.04s )\n",
      "Costs of filter 474:   455 ( 75.82s )\n",
      "Costs of filter 475:   453 ( 77.69s )\n",
      "Costs of filter 476:   514 ( 78.66s )\n",
      "Costs of filter 478:   450 ( 77.23s )\n",
      "Costs of filter 480:   840 ( 76.15s )\n",
      "Costs of filter 481:   625 ( 76.70s )\n",
      "Costs of filter 482:   318 ( 76.85s )\n",
      "Costs of filter 483:   496 ( 75.94s )\n",
      "Costs of filter 484:   313 ( 77.97s )\n",
      "Costs of filter 485:  1004 ( 78.43s )\n",
      "Costs of filter 487:   596 ( 76.68s )\n",
      "Costs of filter 489:   628 ( 78.01s )\n",
      "Costs of filter 490:   641 ( 77.99s )\n",
      "Costs of filter 493:   576 ( 79.04s )\n",
      "Costs of filter 494:   787 ( 79.79s )\n",
      "Costs of filter 495:   637 ( 76.79s )\n",
      "Costs of filter 496:   473 ( 78.76s )\n",
      "Costs of filter 499:   645 ( 80.28s )\n",
      "Costs of filter 500:   784 ( 78.67s )\n",
      "Costs of filter 501:   618 ( 77.93s )\n",
      "Costs of filter 502:   498 ( 80.23s )\n",
      "Costs of filter 503:   448 ( 78.35s )\n",
      "Costs of filter 505:   855 ( 78.09s )\n",
      "Costs of filter 506:   461 ( 78.09s )\n",
      "Costs of filter 509:   449 ( 79.00s )\n",
      "Costs of filter 510:   564 ( 78.11s )\n",
      "Costs of filter 511:   890 ( 76.87s )\n",
      "301 filter processed.\n"
     ]
    }
   ],
   "source": [
    "# the name of the layer we want to visualize\n",
    "# (see model definition at keras/applications/vgg16.py)\n",
    "LAYER_NAME = 'block5_conv1'\n",
    "\n",
    "# build the VGG16 network with ImageNet weights\n",
    "vgg = vgg16.VGG16(weights='imagenet', include_top=False)\n",
    "print('Model loaded.')\n",
    "vgg.summary()\n",
    "\n",
    "# example function call\n",
    "visualize_layer(vgg, LAYER_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
