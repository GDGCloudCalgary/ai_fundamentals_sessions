{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/6%20-%20Transformers%20for%20Sentiment%20Analysis.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "seed = 100\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "have to use the pretrained vocabulary ...any work outside of the pretrained vocab will be a <UNK> token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#!pip install torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.tokenize('hello world !! Let\\'s learn about transformers etc. every sunday till september')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello',\n",
       " 'world',\n",
       " '!',\n",
       " '!',\n",
       " 'let',\n",
       " \"'\",\n",
       " 's',\n",
       " 'learn',\n",
       " 'about',\n",
       " 'transformers',\n",
       " 'etc',\n",
       " '.',\n",
       " 'every',\n",
       " 'sunday',\n",
       " 'till',\n",
       " 'september']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = tokenizer.convert_tokens_to_ids(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7592,\n",
       " 2088,\n",
       " 999,\n",
       " 999,\n",
       " 2292,\n",
       " 1005,\n",
       " 1055,\n",
       " 4553,\n",
       " 2055,\n",
       " 19081,\n",
       " 4385,\n",
       " 1012,\n",
       " 2296,\n",
       " 4465,\n",
       " 6229,\n",
       " 2244]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "max_input_length = tokenizer.max_model_input_sizes['bert-base-uncased']\n",
    "print(max_input_length )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_cut(sentence):\n",
    "    tokens = tokenizer.tokenize(sentence) \n",
    "    tokens = tokens[:max_input_length-2]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using standard dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_token_idx = tokenizer.convert_tokens_to_ids(tokenizer.cls_token)\n",
    "eos_token_idx = tokenizer.convert_tokens_to_ids(tokenizer.sep_token)\n",
    "pad_token_idx = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
    "unk_token_idx = tokenizer.convert_tokens_to_ids(tokenizer.unk_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import data\n",
    "\n",
    "TEXT = data.Field(batch_first = True,\n",
    "                  use_vocab = False,\n",
    "                  tokenize = tokenize_and_cut,\n",
    "                  preprocessing = tokenizer.convert_tokens_to_ids,\n",
    "                  init_token = init_token_idx,\n",
    "                  eos_token = eos_token_idx,\n",
    "                  pad_token = pad_token_idx,\n",
    "                  unk_token = unk_token_idx)\n",
    "\n",
    "LABEL = data.LabelField(dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import datasets\n",
    "\n",
    "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\n",
    "\n",
    "train_data, valid_data = train_data.split(random_state = random.seed(seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 17500\n",
      "Number of validation examples: 7500\n",
      "Number of testing examples: 25000\n",
      "{'text': [16485, 2024, 2205, 13205, 2000, 22017, 2021, 1996, 4378, 2012, 1996, 4361, 2143, 2782, 2187, 1996, 4258, 22581, 2008, 2027, 2052, 3446, 2023, 2143, 1014, 2030, 1015, 2006, 2037, 6830, 8697, 1012, 1996, 18458, 2003, 2008, 1037, 2715, 12127, 2003, 25455, 1037, 5550, 2301, 28458, 2055, 1996, 7459, 1997, 11133, 2015, 1998, 11133, 26636, 2275, 1999, 1996, 6802, 2627, 2043, 2852, 21272, 2015, 2020, 1996, 6259, 4177, 1012, 2551, 1999, 2093, 25492, 2015, 7534, 2116, 6695, 2000, 8970, 9617, 2818, 4948, 22556, 2164, 10021, 1998, 17727, 22648, 14656, 5929, 1998, 14099, 6259, 17105, 2008, 9125, 2428, 2919, 4623, 1012, 10205, 2024, 4055, 2011, 14225, 1998, 2037, 11841, 29235, 2000, 10041, 2594, 9537, 1997, 6204, 2013, 2029, 2892, 1011, 11225, 1998, 4632, 15613, 2521, 19053, 2389, 8146, 13368, 1012, 1996, 2143, 2071, 2031, 2042, 26316, 2004, 1037, 18446, 18750, 3538, 1010, 2029, 2009, 2205, 4876, 12950, 1010, 2021, 20996, 14227, 2121, 1005, 1055, 3947, 4212, 2200, 4257, 1012, 1996, 4378, 4191, 2012, 1996, 4356, 13198, 2021, 4728, 2022, 5302, 7231, 2094, 1996, 4030, 6393, 1012, 1996, 4566, 3310, 2035, 1999, 1037, 5481, 1998, 2003, 5621, 9643, 1012, 2023, 2003, 1037, 20610, 2143, 1998, 1037, 5949, 1997, 2115, 3185, 2183, 2051, 1012], 'label': 'neg'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training examples: {len(train_data)}\")\n",
    "print(f\"Number of validation examples: {len(valid_data)}\")\n",
    "print(f\"Number of testing examples: {len(test_data)}\")\n",
    "print(vars(train_data.examples[6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['canadians', 'are', 'too', 'polite', 'to', 'boo', 'but', 'the', 'audience', 'at', 'the', 'toronto', 'film', 'festival', 'left', 'the', 'theater', 'muttering', 'that', 'they', 'would', 'rate', 'this', 'film', '0', 'or', '1', 'on', 'their', 'voting', 'sheets', '.', 'the', 'premise', 'is', 'that', 'a', 'modern', 'filmmaker', 'is', 'interpreting', 'a', '17th', 'century', 'fable', 'about', 'the', 'loves', 'of', 'shepherd', '##s', 'and', 'shepherd', '##esses', 'set', 'in', 'the', 'distant', 'past', 'when', 'dr', '##uid', '##s', 'were', 'the', 'spiritual', 'leaders', '.', 'working', 'in', 'three', 'epoch', '##s', 'presents', 'many', 'opportunities', 'to', 'introduce', 'ana', '##ch', '##ron', '##isms', 'including', 'silly', 'and', 'imp', '##rac', '##tical', 'clothing', 'and', 'peculiar', 'spiritual', 'rites', 'that', 'involve', 'really', 'bad', 'poetry', '.', 'lovers', 'are', 'divided', 'by', 'jealousy', 'and', 'their', 'rigid', 'adherence', 'to', 'idiot', '##ic', 'codes', 'of', 'conduct', 'from', 'which', 'cross', '-', 'dressing', 'and', 'ass', '##orted', 'far', '##cic', '##al', 'situations', 'arise', '.', 'the', 'film', 'could', 'have', 'been', 'hilarious', 'as', 'a', 'monty', 'python', 'piece', ',', 'which', 'it', 'too', 'closely', 'resembles', ',', 'but', 'ro', '##hm', '##er', \"'\", 's', 'effort', 'falls', 'very', 'flat', '.', 'the', 'audience', 'laughed', 'at', 'the', 'sight', 'jokes', 'but', 'otherwise', 'be', '##mo', '##ane', '##d', 'the', 'slow', 'pace', '.', 'the', 'ending', 'comes', 'all', 'in', 'a', 'rush', 'and', 'is', 'truly', 'awful', '.', 'this', 'is', 'a', 'trivial', 'film', 'and', 'a', 'waste', 'of', 'your', 'movie', 'going', 'time', '.']\n",
      "defaultdict(None, {'pos': 0, 'neg': 1})\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(vars(train_data.examples[6])['text'])\n",
    "\n",
    "print(tokens)\n",
    "\n",
    "LABEL.build_vocab(train_data)\n",
    "\n",
    "print(LABEL.vocab.stoi)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pos', 'neg']\n"
     ]
    }
   ],
   "source": [
    "print(LABEL.vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE, \n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "bert = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTGRUSentiment(nn.Module):\n",
    "    def __init__(self, bert, hidden_dim, output_dim, n_layers, dropout, bidirectional=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.bert = bert\n",
    "        \n",
    "        embedding_dim = bert.config.to_dict()['hidden_size']\n",
    "        \n",
    "        self.rnn = nn.GRU(embedding_dim, hidden_dim,\n",
    "                         num_layers = n_layers, bidirectional = bidirectional,\n",
    "                         batch_first = True, dropout=0 if n_layers < 2 else dropout)\n",
    "        \n",
    "        self.out = nn.Linear(hidden_dim*2 if bidirectional else hidden_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    \n",
    "    def forward(self, text):\n",
    "        \n",
    "        #not updating bert weights\n",
    "        with torch.no_grad():\n",
    "            embedded = self.bert(text)[0]\n",
    "        \n",
    "        _, hidden = self.rnn(embedded)\n",
    "        \n",
    "        if self.rnn.bidirectional:\n",
    "            hidden = self.dropout(torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1))\n",
    "        else:\n",
    "            hidden = self.dropout(hidden[-1, :, :])\n",
    "        \n",
    "        output = self.out(hidden)\n",
    "        return output   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.25\n",
    "\n",
    "\n",
    "model = BERTGRUSentiment(bert, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, DROPOUT, BIDIRECTIONAL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert.embeddings.word_embeddings.weight\n",
      "bert.embeddings.position_embeddings.weight\n",
      "bert.embeddings.token_type_embeddings.weight\n",
      "bert.embeddings.LayerNorm.weight\n",
      "bert.embeddings.LayerNorm.bias\n",
      "bert.encoder.layer.0.attention.self.query.weight\n",
      "bert.encoder.layer.0.attention.self.query.bias\n",
      "bert.encoder.layer.0.attention.self.key.weight\n",
      "bert.encoder.layer.0.attention.self.key.bias\n",
      "bert.encoder.layer.0.attention.self.value.weight\n",
      "bert.encoder.layer.0.attention.self.value.bias\n",
      "bert.encoder.layer.0.attention.output.dense.weight\n",
      "bert.encoder.layer.0.attention.output.dense.bias\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.0.intermediate.dense.weight\n",
      "bert.encoder.layer.0.intermediate.dense.bias\n",
      "bert.encoder.layer.0.output.dense.weight\n",
      "bert.encoder.layer.0.output.dense.bias\n",
      "bert.encoder.layer.0.output.LayerNorm.weight\n",
      "bert.encoder.layer.0.output.LayerNorm.bias\n",
      "bert.encoder.layer.1.attention.self.query.weight\n",
      "bert.encoder.layer.1.attention.self.query.bias\n",
      "bert.encoder.layer.1.attention.self.key.weight\n",
      "bert.encoder.layer.1.attention.self.key.bias\n",
      "bert.encoder.layer.1.attention.self.value.weight\n",
      "bert.encoder.layer.1.attention.self.value.bias\n",
      "bert.encoder.layer.1.attention.output.dense.weight\n",
      "bert.encoder.layer.1.attention.output.dense.bias\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.1.intermediate.dense.weight\n",
      "bert.encoder.layer.1.intermediate.dense.bias\n",
      "bert.encoder.layer.1.output.dense.weight\n",
      "bert.encoder.layer.1.output.dense.bias\n",
      "bert.encoder.layer.1.output.LayerNorm.weight\n",
      "bert.encoder.layer.1.output.LayerNorm.bias\n",
      "bert.encoder.layer.2.attention.self.query.weight\n",
      "bert.encoder.layer.2.attention.self.query.bias\n",
      "bert.encoder.layer.2.attention.self.key.weight\n",
      "bert.encoder.layer.2.attention.self.key.bias\n",
      "bert.encoder.layer.2.attention.self.value.weight\n",
      "bert.encoder.layer.2.attention.self.value.bias\n",
      "bert.encoder.layer.2.attention.output.dense.weight\n",
      "bert.encoder.layer.2.attention.output.dense.bias\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.2.intermediate.dense.weight\n",
      "bert.encoder.layer.2.intermediate.dense.bias\n",
      "bert.encoder.layer.2.output.dense.weight\n",
      "bert.encoder.layer.2.output.dense.bias\n",
      "bert.encoder.layer.2.output.LayerNorm.weight\n",
      "bert.encoder.layer.2.output.LayerNorm.bias\n",
      "bert.encoder.layer.3.attention.self.query.weight\n",
      "bert.encoder.layer.3.attention.self.query.bias\n",
      "bert.encoder.layer.3.attention.self.key.weight\n",
      "bert.encoder.layer.3.attention.self.key.bias\n",
      "bert.encoder.layer.3.attention.self.value.weight\n",
      "bert.encoder.layer.3.attention.self.value.bias\n",
      "bert.encoder.layer.3.attention.output.dense.weight\n",
      "bert.encoder.layer.3.attention.output.dense.bias\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.3.intermediate.dense.weight\n",
      "bert.encoder.layer.3.intermediate.dense.bias\n",
      "bert.encoder.layer.3.output.dense.weight\n",
      "bert.encoder.layer.3.output.dense.bias\n",
      "bert.encoder.layer.3.output.LayerNorm.weight\n",
      "bert.encoder.layer.3.output.LayerNorm.bias\n",
      "bert.encoder.layer.4.attention.self.query.weight\n",
      "bert.encoder.layer.4.attention.self.query.bias\n",
      "bert.encoder.layer.4.attention.self.key.weight\n",
      "bert.encoder.layer.4.attention.self.key.bias\n",
      "bert.encoder.layer.4.attention.self.value.weight\n",
      "bert.encoder.layer.4.attention.self.value.bias\n",
      "bert.encoder.layer.4.attention.output.dense.weight\n",
      "bert.encoder.layer.4.attention.output.dense.bias\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.4.intermediate.dense.weight\n",
      "bert.encoder.layer.4.intermediate.dense.bias\n",
      "bert.encoder.layer.4.output.dense.weight\n",
      "bert.encoder.layer.4.output.dense.bias\n",
      "bert.encoder.layer.4.output.LayerNorm.weight\n",
      "bert.encoder.layer.4.output.LayerNorm.bias\n",
      "bert.encoder.layer.5.attention.self.query.weight\n",
      "bert.encoder.layer.5.attention.self.query.bias\n",
      "bert.encoder.layer.5.attention.self.key.weight\n",
      "bert.encoder.layer.5.attention.self.key.bias\n",
      "bert.encoder.layer.5.attention.self.value.weight\n",
      "bert.encoder.layer.5.attention.self.value.bias\n",
      "bert.encoder.layer.5.attention.output.dense.weight\n",
      "bert.encoder.layer.5.attention.output.dense.bias\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.5.intermediate.dense.weight\n",
      "bert.encoder.layer.5.intermediate.dense.bias\n",
      "bert.encoder.layer.5.output.dense.weight\n",
      "bert.encoder.layer.5.output.dense.bias\n",
      "bert.encoder.layer.5.output.LayerNorm.weight\n",
      "bert.encoder.layer.5.output.LayerNorm.bias\n",
      "bert.encoder.layer.6.attention.self.query.weight\n",
      "bert.encoder.layer.6.attention.self.query.bias\n",
      "bert.encoder.layer.6.attention.self.key.weight\n",
      "bert.encoder.layer.6.attention.self.key.bias\n",
      "bert.encoder.layer.6.attention.self.value.weight\n",
      "bert.encoder.layer.6.attention.self.value.bias\n",
      "bert.encoder.layer.6.attention.output.dense.weight\n",
      "bert.encoder.layer.6.attention.output.dense.bias\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.6.intermediate.dense.weight\n",
      "bert.encoder.layer.6.intermediate.dense.bias\n",
      "bert.encoder.layer.6.output.dense.weight\n",
      "bert.encoder.layer.6.output.dense.bias\n",
      "bert.encoder.layer.6.output.LayerNorm.weight\n",
      "bert.encoder.layer.6.output.LayerNorm.bias\n",
      "bert.encoder.layer.7.attention.self.query.weight\n",
      "bert.encoder.layer.7.attention.self.query.bias\n",
      "bert.encoder.layer.7.attention.self.key.weight\n",
      "bert.encoder.layer.7.attention.self.key.bias\n",
      "bert.encoder.layer.7.attention.self.value.weight\n",
      "bert.encoder.layer.7.attention.self.value.bias\n",
      "bert.encoder.layer.7.attention.output.dense.weight\n",
      "bert.encoder.layer.7.attention.output.dense.bias\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.7.intermediate.dense.weight\n",
      "bert.encoder.layer.7.intermediate.dense.bias\n",
      "bert.encoder.layer.7.output.dense.weight\n",
      "bert.encoder.layer.7.output.dense.bias\n",
      "bert.encoder.layer.7.output.LayerNorm.weight\n",
      "bert.encoder.layer.7.output.LayerNorm.bias\n",
      "bert.encoder.layer.8.attention.self.query.weight\n",
      "bert.encoder.layer.8.attention.self.query.bias\n",
      "bert.encoder.layer.8.attention.self.key.weight\n",
      "bert.encoder.layer.8.attention.self.key.bias\n",
      "bert.encoder.layer.8.attention.self.value.weight\n",
      "bert.encoder.layer.8.attention.self.value.bias\n",
      "bert.encoder.layer.8.attention.output.dense.weight\n",
      "bert.encoder.layer.8.attention.output.dense.bias\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.8.intermediate.dense.weight\n",
      "bert.encoder.layer.8.intermediate.dense.bias\n",
      "bert.encoder.layer.8.output.dense.weight\n",
      "bert.encoder.layer.8.output.dense.bias\n",
      "bert.encoder.layer.8.output.LayerNorm.weight\n",
      "bert.encoder.layer.8.output.LayerNorm.bias\n",
      "bert.encoder.layer.9.attention.self.query.weight\n",
      "bert.encoder.layer.9.attention.self.query.bias\n",
      "bert.encoder.layer.9.attention.self.key.weight\n",
      "bert.encoder.layer.9.attention.self.key.bias\n",
      "bert.encoder.layer.9.attention.self.value.weight\n",
      "bert.encoder.layer.9.attention.self.value.bias\n",
      "bert.encoder.layer.9.attention.output.dense.weight\n",
      "bert.encoder.layer.9.attention.output.dense.bias\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.9.intermediate.dense.weight\n",
      "bert.encoder.layer.9.intermediate.dense.bias\n",
      "bert.encoder.layer.9.output.dense.weight\n",
      "bert.encoder.layer.9.output.dense.bias\n",
      "bert.encoder.layer.9.output.LayerNorm.weight\n",
      "bert.encoder.layer.9.output.LayerNorm.bias\n",
      "bert.encoder.layer.10.attention.self.query.weight\n",
      "bert.encoder.layer.10.attention.self.query.bias\n",
      "bert.encoder.layer.10.attention.self.key.weight\n",
      "bert.encoder.layer.10.attention.self.key.bias\n",
      "bert.encoder.layer.10.attention.self.value.weight\n",
      "bert.encoder.layer.10.attention.self.value.bias\n",
      "bert.encoder.layer.10.attention.output.dense.weight\n",
      "bert.encoder.layer.10.attention.output.dense.bias\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.10.intermediate.dense.weight\n",
      "bert.encoder.layer.10.intermediate.dense.bias\n",
      "bert.encoder.layer.10.output.dense.weight\n",
      "bert.encoder.layer.10.output.dense.bias\n",
      "bert.encoder.layer.10.output.LayerNorm.weight\n",
      "bert.encoder.layer.10.output.LayerNorm.bias\n",
      "bert.encoder.layer.11.attention.self.query.weight\n",
      "bert.encoder.layer.11.attention.self.query.bias\n",
      "bert.encoder.layer.11.attention.self.key.weight\n",
      "bert.encoder.layer.11.attention.self.key.bias\n",
      "bert.encoder.layer.11.attention.self.value.weight\n",
      "bert.encoder.layer.11.attention.self.value.bias\n",
      "bert.encoder.layer.11.attention.output.dense.weight\n",
      "bert.encoder.layer.11.attention.output.dense.bias\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.11.intermediate.dense.weight\n",
      "bert.encoder.layer.11.intermediate.dense.bias\n",
      "bert.encoder.layer.11.output.dense.weight\n",
      "bert.encoder.layer.11.output.dense.bias\n",
      "bert.encoder.layer.11.output.LayerNorm.weight\n",
      "bert.encoder.layer.11.output.LayerNorm.bias\n",
      "bert.pooler.dense.weight\n",
      "bert.pooler.dense.bias\n",
      "rnn.weight_ih_l0\n",
      "rnn.weight_hh_l0\n",
      "rnn.bias_ih_l0\n",
      "rnn.bias_hh_l0\n",
      "rnn.weight_ih_l0_reverse\n",
      "rnn.weight_hh_l0_reverse\n",
      "rnn.bias_ih_l0_reverse\n",
      "rnn.bias_hh_l0_reverse\n",
      "rnn.weight_ih_l1\n",
      "rnn.weight_hh_l1\n",
      "rnn.bias_ih_l1\n",
      "rnn.bias_hh_l1\n",
      "rnn.weight_ih_l1_reverse\n",
      "rnn.weight_hh_l1_reverse\n",
      "rnn.bias_ih_l1_reverse\n",
      "rnn.bias_hh_l1_reverse\n",
      "out.weight\n",
      "out.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name)\n",
    "    if name.startswith('bert'):\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 2,759,169 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn.weight_ih_l0\n",
      "rnn.weight_hh_l0\n",
      "rnn.bias_ih_l0\n",
      "rnn.bias_hh_l0\n",
      "rnn.weight_ih_l0_reverse\n",
      "rnn.weight_hh_l0_reverse\n",
      "rnn.bias_ih_l0_reverse\n",
      "rnn.bias_hh_l0_reverse\n",
      "rnn.weight_ih_l1\n",
      "rnn.weight_hh_l1\n",
      "rnn.bias_ih_l1\n",
      "rnn.bias_hh_l1\n",
      "rnn.weight_ih_l1_reverse\n",
      "rnn.weight_hh_l1_reverse\n",
      "rnn.bias_ih_l1_reverse\n",
      "rnn.bias_hh_l1_reverse\n",
      "out.weight\n",
      "out.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():                \n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        print(batch.text.size())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(batch.text).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch.label)\n",
    "        \n",
    "        acc = binary_accuracy(predictions, batch.label)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            predictions = model(batch.text).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, batch.label)\n",
    "            \n",
    "            acc = binary_accuracy(predictions, batch.label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 446])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 381])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 425])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 495])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 490])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 322])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 495])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 473])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 455])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 413])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 493])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 386])\n",
      "torch.Size([16, 398])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 426])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 481])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 510])\n",
      "torch.Size([16, 499])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 355])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 476])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 356])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 387])\n",
      "torch.Size([16, 433])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 436])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 422])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 426])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 434])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 392])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 491])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 497])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 493])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 472])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 442])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 423])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 508])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 497])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 468])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 362])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 507])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 398])\n",
      "torch.Size([16, 433])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 438])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 411])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 421])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 317])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 456])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 476])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 458])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 463])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 505])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 476])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 443])\n",
      "torch.Size([16, 464])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 456])\n",
      "torch.Size([16, 495])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 457])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 454])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 401])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 505])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 277])\n",
      "torch.Size([16, 442])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 470])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 501])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 465])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 447])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 491])\n",
      "torch.Size([16, 376])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 495])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 391])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 455])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 384])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([12, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 486])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 420])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 505])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 470])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 383])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 503])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "Epoch: 01 | Epoch Time: 439m 28s\n",
      "\tTrain Loss: 0.370 | Train Acc: 83.04%\n",
      "\t Val. Loss: 0.231 |  Val. Acc: 91.13%\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 460])\n",
      "torch.Size([16, 420])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 363])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 360])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 450])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 462])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 489])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 398])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 413])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 503])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 508])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 453])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 391])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 495])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 505])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 471])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 503])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 400])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 375])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 347])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 464])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 435])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 483])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 498])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 480])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 501])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 483])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 488])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 473])\n",
      "torch.Size([16, 505])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 424])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 482])\n",
      "torch.Size([16, 452])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 439])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 485])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 414])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 510])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 465])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 491])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 447])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 505])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 385])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 436])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 465])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 478])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 378])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 462])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 461])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 472])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 477])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 366])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 353])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 5\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "        \n",
    "    end_time = time.time()\n",
    "        \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "        \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut6-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('tut6-model.pt'))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(model, tokenizer, sentence):\n",
    "    model.eval()\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    tokens = tokens[:max_input_length-2]\n",
    "    indexed = [init_token_idx] + tokenizer.convert_tokens_to_ids(tokens) + [eos_token_idx]\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(0)\n",
    "    prediction = torch.sigmoid(model(tensor))\n",
    "    return prediction.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_sentiment(model, tokenizer, \"This film is terrible\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_sentiment(model, tokenizer, \"This film is great\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
