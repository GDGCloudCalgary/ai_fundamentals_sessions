{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "#https://pytorch.org/docs/stable/data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72f30c1ae39846628d868708d4ee3b85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\train-images-idx3-ubyte.gz to MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99858ef8d884417eac55a834bdb6e763",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\train-labels-idx1-ubyte.gz to MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST\\raw\\t10k-images-idx3-ubyte.gz\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8794006281154a06b267e24af2804472",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\t10k-images-idx3-ubyte.gz to MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "956c3c6292f2445a8b76b268915f7870",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\t10k-labels-idx1-ubyte.gz to MNIST\\raw\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\torch\\csrc\\utils\\tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train = datasets.MNIST(\"\", train=True, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "test = datasets.MNIST(\"\", train=False, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets.MNIST?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchvision.datasets.mnist.MNIST"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.utils.data.DataLoader(train, batch_size=32, shuffle=True)\n",
    "test = torch.utils.data.DataLoader(test, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.dataloader.DataLoader"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: \n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataLoader' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-9b7c4a596534>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'DataLoader' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-ceb0fd914716>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "x = list(train)[0]\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4745, 0.9922,\n",
       "          0.6235, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4745, 0.9882,\n",
       "          0.6196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4745, 0.9882,\n",
       "          0.9490, 0.1373, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4745, 0.9882,\n",
       "          0.9882, 0.1529, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6078, 0.9882,\n",
       "          0.9882, 0.1529, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9922, 0.9882,\n",
       "          0.9882, 0.1529, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9922, 0.9882,\n",
       "          0.7373, 0.0510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3333, 0.9922, 0.9882,\n",
       "          0.6196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5216, 0.9922, 0.9882,\n",
       "          0.6196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5216, 0.9922, 0.9882,\n",
       "          0.6196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0275, 0.7451, 1.0000, 0.9922,\n",
       "          0.6235, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0549, 0.9882, 0.9922, 0.9882,\n",
       "          0.6196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.5216, 0.9882, 0.9922, 0.9882,\n",
       "          0.4314, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0902, 0.9255, 0.9882, 0.9922, 0.6314,\n",
       "          0.0157, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.1059, 0.9882, 0.9882, 0.9922, 0.5686,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.1059, 0.9882, 0.9882, 0.9922, 0.4627,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.1882, 0.9882, 0.9882, 0.9922, 0.0510,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.1020, 0.8549, 0.9882, 0.9882, 0.9412, 0.0431,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.4627, 0.9882, 0.9882, 0.9882, 0.5216, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.6784, 0.9882, 0.9882, 0.9882, 0.2471, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 7, 7, 4, 5, 4, 2, 9, 5, 9, 8, 2, 1, 2, 0, 6, 4, 4, 6, 0, 7, 7, 2, 4,\n",
       "        6, 0, 3, 0, 6, 6, 6, 5])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "first element\n",
      "32 <class 'torch.Tensor'>\n",
      "second element\n",
      "32 <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "for d in train:\n",
    "    print(len(d))\n",
    "    print(\"first element\")\n",
    "    print(len(d[0]), type(d[0]))\n",
    "    print(\"second element\")\n",
    "    print(len(d[1]), type(d[1]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "first element\n",
      "torch.Size([32, 1, 28, 28])\n",
      "second element\n",
      "torch.Size([32])\n",
      "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]])\n",
      "<class 'torch.Tensor'> torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "for d in train:\n",
    "    print(len(d))\n",
    "    print(\"first element\")\n",
    "    print(d[0].size())\n",
    "    print(\"second element\")\n",
    "    print(d[1].size())\n",
    "    print(d[0])\n",
    "    print(type(d[0][0]), d[0][0].size())\n",
    "    img = d[0][0]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#visualize the image\n",
    "img = img.view(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 28, 28])\n",
      "torch.Size([32])\n",
      "tensor([8, 9, 1, 2, 6, 7, 1, 4, 7, 4, 9, 7, 3, 2, 5, 4, 4, 1, 9, 5, 8, 5, 0, 9,\n",
      "        8, 9, 2, 9, 3, 6, 8, 0])\n",
      "tensor([8, 9, 1, 2, 6, 7, 1, 4, 7, 4, 9, 7, 3, 2, 5, 4, 4, 1, 9, 5, 8, 5, 0, 9,\n",
      "        8, 9, 2, 9, 3, 6, 8, 0])\n",
      "tensor([[8, 9, 1, 2, 6, 7, 1, 4, 7, 4, 9, 7, 3, 2, 5, 4, 4, 1, 9, 5, 8, 5, 0, 9,\n",
      "         8, 9, 2, 9, 3, 6, 8, 0]])\n",
      "tensor([[8, 9, 1,  ..., 6, 8, 0],\n",
      "        [4, 7, 8,  ..., 0, 8, 5],\n",
      "        [0, 3, 2,  ..., 3, 3, 6],\n",
      "        ...,\n",
      "        [8, 2, 0,  ..., 9, 1, 4],\n",
      "        [3, 9, 0,  ..., 8, 3, 2],\n",
      "        [6, 8, 3,  ..., 8, 1, 2]])\n",
      "tensor([[[8, 9, 1,  ..., 6, 8, 0]],\n",
      "\n",
      "        [[4, 7, 8,  ..., 0, 8, 5]],\n",
      "\n",
      "        [[0, 3, 2,  ..., 3, 3, 6]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[8, 2, 0,  ..., 9, 1, 4]],\n",
      "\n",
      "        [[3, 9, 0,  ..., 8, 3, 2]],\n",
      "\n",
      "        [[6, 8, 3,  ..., 8, 1, 2]]])\n",
      "tensor([[[8, 9, 1,  ..., 6, 8, 0],\n",
      "         [4, 7, 8,  ..., 0, 8, 5],\n",
      "         [0, 3, 2,  ..., 3, 3, 6],\n",
      "         ...,\n",
      "         [8, 2, 0,  ..., 9, 1, 4],\n",
      "         [3, 9, 0,  ..., 8, 3, 2],\n",
      "         [6, 8, 3,  ..., 8, 1, 2]]])\n",
      "tensor([[8, 9, 1,  ..., 6, 8, 0],\n",
      "        [4, 7, 8,  ..., 0, 8, 5],\n",
      "        [0, 3, 2,  ..., 3, 3, 6],\n",
      "        ...,\n",
      "        [8, 2, 0,  ..., 9, 1, 4],\n",
      "        [3, 9, 0,  ..., 8, 3, 2],\n",
      "        [6, 8, 3,  ..., 8, 1, 2]])\n",
      "tensor([[8, 9, 1,  ..., 6, 8, 0],\n",
      "        [4, 7, 8,  ..., 0, 8, 5],\n",
      "        [0, 3, 2,  ..., 3, 3, 6],\n",
      "        ...,\n",
      "        [8, 2, 0,  ..., 9, 1, 4],\n",
      "        [3, 9, 0,  ..., 8, 3, 2],\n",
      "        [6, 8, 3,  ..., 8, 1, 2]])\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for d in train:\n",
    "    if i==0:\n",
    "        print(d[0].size())\n",
    "        print(d[0].squeeze(0).size())\n",
    "        print(d[0].squeeze(1).size())\n",
    "        print(d[1].size())\n",
    "        print(d[1])\n",
    "        print(d[1].squeeze(0))\n",
    "        print(d[1].unsqueeze(0))\n",
    "        all_labels = d[1].unsqueeze(0)\n",
    "    else:\n",
    "        all_labels = torch.cat((all_labels, d[1].unsqueeze(0)),0)\n",
    "    i=i+1\n",
    "print(all_labels)\n",
    "print(all_labels.unsqueeze(1))\n",
    "print(all_labels.unsqueeze(0))\n",
    "print(all_labels.squeeze(1))\n",
    "print(all_labels.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[8],\n",
      "        [9],\n",
      "        [1],\n",
      "        ...,\n",
      "        [8],\n",
      "        [1],\n",
      "        [2]])\n",
      "tensor([[8, 9, 1,  ..., 8, 1, 2]])\n",
      "tensor([8, 9, 1,  ..., 8, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "print(all_labels.view((-1,1)))\n",
    "print(all_labels.view((1,-1)))\n",
    "print(all_labels.view((1,-1)).squeeze(0))\n",
    "all_labels = all_labels.view((1,-1)).squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0) 5923 9.871666666666666\n",
      "tensor(1) 6742 11.236666666666666\n",
      "tensor(2) 5958 9.93\n",
      "tensor(3) 6131 10.218333333333334\n",
      "tensor(4) 5842 9.736666666666666\n",
      "tensor(5) 5421 9.035\n",
      "tensor(6) 5918 9.863333333333333\n",
      "tensor(7) 6265 10.441666666666666\n",
      "tensor(8) 5851 9.751666666666667\n",
      "tensor(9) 5949 9.915\n",
      "60000\n"
     ]
    }
   ],
   "source": [
    "totc = 0\n",
    "count = len(all_labels)\n",
    "for i in torch.unique(all_labels):\n",
    "    tmp = ((all_labels == i).sum(dim=0).item())\n",
    "    print(i, tmp, 100*tmp/count)\n",
    "    totc += tmp \n",
    "print(totc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totc == len(train)*32 == len(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#neural_network classes\n",
    "import torch.nn as nn\n",
    "#mathematical functions (helper functions)\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a Neural Network Child class where parent is implemented in torch.nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0000000011111\n",
    "y00000000wwwwww\n",
    "yb1b1b1b1wwwww"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#28*28 = 784\n",
    "class Hidden3Layer_MLP_Flattened_Image_Net(nn.Module):\n",
    "    def __init__(self,no_neurons=64,dims_img=(), no_out_classes=0):\n",
    "        #initialize with the parent class' default implementation\n",
    "        super().__init__()\n",
    "        #First Fully Connected Layer - Takes Images as Input \n",
    "        self.fc1 = nn.Linear(dims_img[0]*dims_img[1],no_neurons)\n",
    "        self.fc2 = nn.Linear(no_neurons,no_neurons)\n",
    "        self.fc3 = nn.Linear(no_neurons,no_neurons)\n",
    "        self.fc4 = nn.Linear(no_neurons, no_out_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        prediction_distribution = F.log_softmax(x, dim=1)\n",
    "        return prediction_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_obj = Hidden3Layer_MLP_Flattened_Image_Net(no_neurons=64,dims_img=(28,28), no_out_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9444, 0.2847, 0.5630, 0.7415, 0.6831, 0.3686, 0.6405, 0.1688, 0.5005,\n",
      "         0.3582, 0.2398, 0.9303, 0.2103, 0.4318, 0.0736, 0.2750, 0.1830, 0.3679,\n",
      "         0.5464, 0.9332, 0.8651, 0.5702, 0.5278, 0.7454, 0.3735, 0.9570, 0.0834,\n",
      "         0.3303, 0.9876, 0.8339, 0.6717, 0.3223, 0.0726, 0.9172, 0.2592, 0.3609,\n",
      "         0.1791, 0.2818, 0.1810, 0.9365, 0.2206, 0.4564, 0.0797, 0.0557, 0.1831,\n",
      "         0.8243, 0.5981, 0.9669, 0.6705, 0.0928, 0.4781, 0.5681, 0.7104, 0.5108,\n",
      "         0.8607, 0.4428, 0.6072, 0.4689, 0.2290, 0.9836, 0.5192, 0.4430, 0.5232,\n",
      "         0.7712, 0.4668, 0.6552, 0.7659, 0.1537, 0.6668, 0.7934, 0.0849, 0.3460,\n",
      "         0.7782, 0.3228, 0.1588, 0.3787, 0.5229, 0.0908, 0.3977, 0.9770, 0.8897,\n",
      "         0.1395, 0.4307, 0.4822, 0.0263, 0.6711, 0.1038, 0.9011, 0.0186, 0.4575,\n",
      "         0.4655, 0.3511, 0.4700, 0.0036, 0.3974, 0.6193, 0.4086, 0.1053, 0.2329,\n",
      "         0.0543, 0.4743, 0.9514, 0.7572, 0.0652, 0.0368, 0.1487, 0.7828, 0.4220,\n",
      "         0.8253, 0.0271, 0.0519, 0.7534, 0.9726, 0.6359, 0.2962, 0.3363, 0.0964,\n",
      "         0.3579, 0.4834, 0.0608, 0.6460, 0.1640, 0.9146, 0.2069, 0.6864, 0.8872,\n",
      "         0.8406, 0.2514, 0.7763, 0.5294, 0.3328, 0.4301, 0.4424, 0.8733, 0.3153,\n",
      "         0.5465, 0.7923, 0.9596, 0.3105, 0.1863, 0.4325, 0.7341, 0.4383, 0.1728,\n",
      "         0.8284, 0.5576, 0.5567, 0.0422, 0.6666, 0.6139, 0.4587, 0.5665, 0.7490,\n",
      "         0.1318, 0.8665, 0.9445, 0.1640, 0.2759, 0.4701, 0.9728, 0.1156, 0.6465,\n",
      "         0.7263, 0.2397, 0.7420, 0.9558, 0.5977, 0.6187, 0.7260, 0.3381, 0.9800,\n",
      "         0.9587, 0.8095, 0.1102, 0.2370, 0.2330, 0.9479, 0.0335, 0.9778, 0.0127,\n",
      "         0.4702, 0.1507, 0.7408, 0.1146, 0.0266, 0.1661, 0.7798, 0.0644, 0.5608,\n",
      "         0.9096, 0.4582, 0.7268, 0.3476, 0.0304, 0.4247, 0.2206, 0.7827, 0.2213,\n",
      "         0.9559, 0.9598, 0.9216, 0.3837, 0.2036, 0.4435, 0.3229, 0.4148, 0.9758,\n",
      "         0.1689, 0.8283, 0.7829, 0.1435, 0.4576, 0.3661, 0.6969, 0.0522, 0.1915,\n",
      "         0.6415, 0.8949, 0.3102, 0.5086, 0.7136, 0.5903, 0.6771, 0.2554, 0.9521,\n",
      "         0.2313, 0.0196, 0.5540, 0.5677, 0.5885, 0.6556, 0.6105, 0.9156, 0.6005,\n",
      "         0.5694, 0.1992, 0.9213, 0.8621, 0.8109, 0.3198, 0.2300, 0.8562, 0.3647,\n",
      "         0.2471, 0.1684, 0.0319, 0.2629, 0.4669, 0.5384, 0.2007, 0.6502, 0.0307,\n",
      "         0.9496, 0.8411, 0.4652, 0.9343, 0.6797, 0.0981, 0.0623, 0.0106, 0.6803,\n",
      "         0.2007, 0.2817, 0.4906, 0.3764, 0.9648, 0.1942, 0.9791, 0.2862, 0.0053,\n",
      "         0.5741, 0.5611, 0.0035, 0.8589, 0.6279, 0.1335, 0.1690, 0.8034, 0.1963,\n",
      "         0.5053, 0.4426, 0.2722, 0.3591, 0.4468, 0.7118, 0.0638, 0.5414, 0.7069,\n",
      "         0.2356, 0.7195, 0.2743, 0.3485, 0.2148, 0.9102, 0.3463, 0.2771, 0.5015,\n",
      "         0.2167, 0.1629, 0.4614, 0.3213, 0.9399, 0.1675, 0.9144, 0.1871, 0.3007,\n",
      "         0.7563, 0.0779, 0.1295, 0.2903, 0.2607, 0.2164, 0.7661, 0.2333, 0.7627,\n",
      "         0.1901, 0.1744, 0.8691, 0.7388, 0.0072, 0.6798, 0.0616, 0.2595, 0.1262,\n",
      "         0.4764, 0.8252, 0.2863, 0.7101, 0.1382, 0.9842, 0.7459, 0.7134, 0.4130,\n",
      "         0.5545, 0.4511, 0.2276, 0.4905, 0.0499, 0.1018, 0.9806, 0.9415, 0.3334,\n",
      "         0.2604, 0.7333, 0.1459, 0.0994, 0.1649, 0.4466, 0.1917, 0.8900, 0.2195,\n",
      "         0.5026, 0.5704, 0.3240, 0.8870, 0.5407, 0.9140, 0.5922, 0.2028, 0.3538,\n",
      "         0.6466, 0.1633, 0.5907, 0.5049, 0.8050, 0.4378, 0.5292, 0.1249, 0.5818,\n",
      "         0.3071, 0.9713, 0.5492, 0.7401, 0.8773, 0.9989, 0.0433, 0.4082, 0.3714,\n",
      "         0.5725, 0.7612, 0.6946, 0.4853, 0.2312, 0.8898, 0.9026, 0.6714, 0.7610,\n",
      "         0.5863, 0.1192, 0.5692, 0.5377, 0.9124, 0.8342, 0.9279, 0.8680, 0.6980,\n",
      "         0.3013, 0.2642, 0.4482, 0.6614, 0.5584, 0.9731, 0.9537, 0.0192, 0.4335,\n",
      "         0.0555, 0.4305, 0.9715, 0.9511, 0.6671, 0.5479, 0.2995, 0.2257, 0.8062,\n",
      "         0.1352, 0.2604, 0.2969, 0.6607, 0.9161, 0.5216, 0.5692, 0.8724, 0.4505,\n",
      "         0.4451, 0.8945, 0.0583, 0.7299, 0.8566, 0.1702, 0.0146, 0.1132, 0.8389,\n",
      "         0.4342, 0.7626, 0.5055, 0.4261, 0.7466, 0.1056, 0.3412, 0.2889, 0.5468,\n",
      "         0.6287, 0.0179, 0.0930, 0.3779, 0.4696, 0.2197, 0.0798, 0.7054, 0.7777,\n",
      "         0.8380, 0.9071, 0.3148, 0.5363, 0.5158, 0.7328, 0.6511, 0.7618, 0.0137,\n",
      "         0.1818, 0.4467, 0.3385, 0.6974, 0.8222, 0.3872, 0.9271, 0.9240, 0.6593,\n",
      "         0.2835, 0.8469, 0.8124, 0.3575, 0.0323, 0.1100, 0.4837, 0.5241, 0.1928,\n",
      "         0.7336, 0.2306, 0.6460, 0.1898, 0.4053, 0.6489, 0.4848, 0.0991, 0.7115,\n",
      "         0.9830, 0.2329, 0.1954, 0.0501, 0.3870, 0.4463, 0.5958, 0.9574, 0.5197,\n",
      "         0.7769, 0.7303, 0.9674, 0.3181, 0.0610, 0.8529, 0.2709, 0.5327, 0.3233,\n",
      "         0.0548, 0.5003, 0.9216, 0.8789, 0.4274, 0.7942, 0.8568, 0.4158, 0.7756,\n",
      "         0.7636, 0.1286, 0.0712, 0.2851, 0.0768, 0.3711, 0.2963, 0.2230, 0.6150,\n",
      "         0.9543, 0.8611, 0.0221, 0.9421, 0.2520, 0.7059, 0.2041, 0.7983, 0.1006,\n",
      "         0.8180, 0.0734, 0.6803, 0.3411, 0.9361, 0.2468, 0.3642, 0.1205, 0.6635,\n",
      "         0.3763, 0.7465, 0.1100, 0.3343, 0.1994, 0.7699, 0.9740, 0.5012, 0.4406,\n",
      "         0.4000, 0.9586, 0.9956, 0.4735, 0.7500, 0.4131, 0.4919, 0.9465, 0.0708,\n",
      "         0.8751, 0.3914, 0.6906, 0.4759, 0.1369, 0.7576, 0.4835, 0.9978, 0.9648,\n",
      "         0.5576, 0.2559, 0.7028, 0.3288, 0.8629, 0.6011, 0.8481, 0.6344, 0.8062,\n",
      "         0.6075, 0.9375, 0.9160, 0.7548, 0.0348, 0.8419, 0.3808, 0.5766, 0.2364,\n",
      "         0.0132, 0.3076, 0.4695, 0.2986, 0.3420, 0.9303, 0.2812, 0.2403, 0.7302,\n",
      "         0.4397, 0.9501, 0.3221, 0.8605, 0.0676, 0.9237, 0.9898, 0.2024, 0.0828,\n",
      "         0.0782, 0.0455, 0.1676, 0.0630, 0.1877, 0.8277, 0.1097, 0.3232, 0.5541,\n",
      "         0.2329, 0.7475, 0.9062, 0.3054, 0.9778, 0.9551, 0.9899, 0.1377, 0.2701,\n",
      "         0.7431, 0.0814, 0.1213, 0.0806, 0.1697, 0.8720, 0.5772, 0.1262, 0.8905,\n",
      "         0.5798, 0.2701, 0.3611, 0.7579, 0.4309, 0.7988, 0.9348, 0.0092, 0.3684,\n",
      "         0.0092, 0.3789, 0.0107, 0.8188, 0.7707, 0.4410, 0.9360, 0.6352, 0.3936,\n",
      "         0.7831, 0.1974, 0.3889, 0.0265, 0.3344, 0.2540, 0.9916, 0.4319, 0.0833,\n",
      "         0.8729, 0.6872, 0.8443, 0.5514, 0.0930, 0.0361, 0.9066, 0.5357, 0.9936,\n",
      "         0.3271, 0.2872, 0.9141, 0.7920, 0.1543, 0.5281, 0.8356, 0.3416, 0.6386,\n",
      "         0.7657, 0.2092, 0.7126, 0.9627, 0.8362, 0.0860, 0.9140, 0.1927, 0.2854,\n",
      "         0.8395, 0.3714, 0.6153, 0.9077, 0.3110, 0.4706, 0.0259, 0.9457, 0.0369,\n",
      "         0.8322, 0.0801, 0.6711, 0.8711, 0.6277, 0.0853, 0.3143, 0.8621, 0.6816,\n",
      "         0.9040, 0.2450, 0.4683, 0.5518, 0.5360, 0.1347, 0.2460, 0.4039, 0.8790,\n",
      "         0.9675, 0.9403, 0.7020, 0.2819, 0.3641, 0.8079, 0.1371, 0.6438, 0.7109,\n",
      "         0.1418, 0.3633, 0.5089, 0.8288, 0.8374, 0.4076, 0.5150, 0.5165, 0.0144,\n",
      "         0.4261, 0.1174, 0.3301, 0.1223, 0.5134, 0.1314, 0.6806, 0.1273, 0.7727,\n",
      "         0.6642, 0.6727, 0.5779, 0.7211, 0.1030, 0.2043, 0.7221, 0.0131, 0.8134,\n",
      "         0.3517, 0.4163, 0.7852, 0.5980, 0.9633, 0.1598, 0.8351, 0.4707, 0.1415,\n",
      "         0.6975, 0.2138, 0.4535, 0.5239, 0.3977, 0.3010, 0.3236, 0.7564, 0.1022,\n",
      "         0.0837, 0.5195, 0.1675, 0.1507, 0.7000, 0.7088, 0.3240, 0.4364, 0.2478,\n",
      "         0.6467, 0.8009, 0.6113, 0.9573, 0.7901, 0.8081, 0.7361, 0.1904, 0.6636,\n",
      "         0.9927]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3636, -2.3946, -2.2697, -2.3457, -2.2722, -2.3748, -2.2840, -2.2821,\n",
       "         -2.2495, -2.2067]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.rand(28,28).view(1,-1)\n",
    "print(X)\n",
    "net_obj.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9674, 0.0728, 0.0914, 0.3900, 0.1886, 0.1736, 0.5791, 0.6025, 0.3530,\n",
      "         0.9271, 0.2989, 0.8079, 0.3475, 0.6194, 0.0816, 0.3355, 0.2879, 0.1861,\n",
      "         0.2293, 0.8659, 0.0749, 0.7573, 0.0587, 0.3842, 0.9065, 0.1312, 0.6402,\n",
      "         0.7096, 0.6363, 0.4084, 0.2759, 0.2305, 0.0199, 0.6621, 0.7110, 0.8906,\n",
      "         0.6553, 0.9354, 0.0907, 0.0820, 0.9850, 0.8167, 0.0892, 0.8517, 0.2353,\n",
      "         0.2882, 0.4894, 0.2676, 0.5041, 0.5636, 0.0408, 0.3802, 0.0879, 0.4940,\n",
      "         0.5246, 0.2460, 0.2422, 0.5685, 0.7572, 0.5574, 0.6966, 0.2341, 0.4877,\n",
      "         0.3168, 0.7278, 0.5014, 0.8831, 0.9333, 0.1968, 0.1391, 0.0496, 0.1844,\n",
      "         0.9848, 0.6089, 0.9176, 0.5377, 0.0670, 0.5175, 0.1748, 0.2286, 0.4800,\n",
      "         0.8353, 0.5668, 0.1656, 0.2284, 0.5371, 0.4806, 0.8901, 0.8746, 0.3441,\n",
      "         0.7008, 0.9415, 0.2909, 0.0487, 0.1518, 0.7816, 0.0778, 0.7525, 0.5714,\n",
      "         0.4182, 0.4315, 0.0438, 0.9900, 0.0390, 0.8296, 0.6521, 0.2706, 0.7300,\n",
      "         0.7465, 0.2673, 0.5332, 0.5010, 0.6650, 0.2316, 0.9658, 0.5773, 0.5891,\n",
      "         0.5744, 0.6005, 0.7816, 0.9477, 0.3424, 0.6743, 0.8085, 0.3862, 0.2361,\n",
      "         0.5920, 0.8667, 0.4291, 0.2545, 0.9592, 0.1530, 0.3617, 0.2452, 0.8742,\n",
      "         0.8238, 0.6244, 0.9976, 0.8552, 0.7793, 0.6439, 0.1940, 0.7185, 0.0848,\n",
      "         0.5723, 0.3100, 0.9153, 0.2621, 0.5298, 0.6371, 0.8093, 0.7172, 0.0672,\n",
      "         0.1064, 0.3761, 0.7695, 0.4868, 0.8693, 0.6327, 0.2961, 0.0910, 0.2144,\n",
      "         0.4663, 0.7506, 0.5878, 0.4450, 0.1846, 0.1698, 0.0616, 0.5880, 0.5713,\n",
      "         0.9132, 0.0786, 0.6513, 0.6262, 0.0847, 0.6345, 0.1035, 0.5320, 0.9774,\n",
      "         0.5920, 0.9564, 0.4906, 0.3298, 0.8667, 0.4785, 0.3471, 0.9217, 0.2356,\n",
      "         0.6221, 0.1163, 0.5139, 0.6874, 0.1723, 0.5744, 0.8333, 0.6355, 0.5485,\n",
      "         0.6469, 0.8125, 0.4449, 0.7676, 0.9307, 0.2288, 0.3727, 0.8506, 0.7865,\n",
      "         0.6605, 0.6744, 0.5134, 0.1978, 0.2760, 0.2004, 0.9999, 0.3719, 0.1384,\n",
      "         0.4989, 0.9679, 0.3691, 0.6830, 0.6574, 0.5956, 0.8311, 0.8827, 0.5500,\n",
      "         0.9993, 0.4684, 0.1256, 0.6519, 0.1105, 0.4523, 0.4218, 0.9064, 0.6492,\n",
      "         0.4340, 0.8038, 0.9452, 0.1915, 0.2040, 0.1458, 0.2225, 0.5638, 0.7106,\n",
      "         0.3174, 0.5178, 0.9074, 0.3910, 0.6828, 0.7729, 0.6428, 0.5603, 0.9826,\n",
      "         0.6946, 0.2588, 0.8874, 0.8016, 0.0277, 0.2643, 0.0173, 0.1647, 0.4492,\n",
      "         0.1028, 0.8013, 0.6555, 0.4528, 0.2159, 0.1651, 0.8093, 0.9410, 0.7753,\n",
      "         0.1242, 0.7584, 0.6276, 0.2902, 0.7217, 0.0397, 0.4779, 0.1814, 0.9577,\n",
      "         0.6933, 0.4965, 0.6762, 0.2128, 0.8177, 0.9935, 0.1430, 0.4875, 0.0867,\n",
      "         0.6613, 0.1401, 0.1752, 0.7989, 0.9437, 0.6770, 0.9261, 0.1060, 0.1937,\n",
      "         0.1926, 0.0123, 0.8465, 0.0544, 0.0122, 0.9240, 0.6968, 0.5436, 0.6117,\n",
      "         0.5188, 0.1171, 0.3343, 0.4425, 0.4418, 0.9679, 0.6302, 0.2253, 0.0396,\n",
      "         0.5623, 0.6825, 0.2820, 0.4956, 0.1159, 0.2485, 0.9495, 0.1697, 0.9518,\n",
      "         0.0072, 0.1093, 0.0388, 0.6214, 0.6471, 0.0966, 0.9025, 0.2851, 0.9319,\n",
      "         0.8802, 0.9626, 0.0971, 0.6403, 0.7091, 0.9876, 0.5535, 0.4929, 0.4129,\n",
      "         0.2493, 0.2468, 0.0332, 0.8115, 0.9538, 0.0420, 0.9219, 0.8715, 0.6696,\n",
      "         0.6416, 0.0514, 0.0402, 0.6518, 0.7338, 0.2875, 0.8886, 0.8906, 0.3121,\n",
      "         0.8193, 0.2593, 0.6728, 0.8940, 0.8970, 0.4179, 0.6193, 0.3725, 0.6200,\n",
      "         0.0751, 0.8983, 0.0301, 0.0955, 0.3336, 0.4039, 0.2086, 0.8664, 0.4337,\n",
      "         0.7614, 0.9172, 0.6368, 0.7499, 0.0276, 0.4207, 0.8414, 0.9154, 0.8335,\n",
      "         0.4336, 0.0919, 0.2595, 0.7556, 0.9682, 0.1675, 0.9226, 0.0204, 0.9421,\n",
      "         0.6585, 0.2800, 0.3020, 0.1643, 0.9358, 0.6556, 0.3040, 0.0682, 0.4166,\n",
      "         0.8763, 0.2421, 0.0434, 0.6272, 0.4215, 0.0259, 0.1185, 0.5769, 0.3801,\n",
      "         0.5979, 0.7864, 0.1276, 0.8807, 0.8312, 0.1329, 0.1888, 0.8913, 0.7606,\n",
      "         0.0702, 0.3474, 0.2078, 0.6874, 0.5285, 0.9775, 0.9555, 0.5093, 0.9000,\n",
      "         0.7763, 0.0877, 0.4545, 0.7878, 0.1357, 0.7626, 0.5609, 0.8608, 0.2476,\n",
      "         0.3509, 0.7508, 0.5171, 0.7483, 0.5455, 0.3588, 0.4857, 0.7477, 0.8483,\n",
      "         0.8108, 0.1984, 0.8536, 0.8618, 0.7699, 0.9099, 0.5115, 0.3626, 0.2864,\n",
      "         0.8490, 0.5589, 0.1233, 0.2187, 0.5729, 0.3473, 0.1060, 0.8501, 0.9935,\n",
      "         0.0549, 0.4069, 0.8076, 0.5212, 0.5539, 0.5323, 0.5095, 0.6398, 0.2154,\n",
      "         0.8343, 0.1057, 0.4306, 0.1874, 0.8877, 0.2504, 0.9014, 0.0019, 0.6806,\n",
      "         0.1326, 0.7306, 0.4837, 0.8997, 0.2859, 0.7641, 0.8340, 0.5718, 0.2765,\n",
      "         0.9300, 0.1102, 0.5834, 0.9435, 0.8133, 0.1545, 0.3845, 0.2718, 0.4349,\n",
      "         0.1209, 0.0240, 0.5342, 0.6177, 0.7054, 0.8625, 0.8871, 0.9654, 0.7836,\n",
      "         0.7877, 0.0717, 0.4840, 0.1319, 0.0630, 0.7050, 0.2242, 0.6664, 0.9983,\n",
      "         0.8769, 0.9636, 0.8656, 0.9521, 0.6650, 0.4234, 0.9616, 0.0617, 0.8535,\n",
      "         0.2726, 0.8836, 0.4864, 0.8095, 0.7350, 0.8659, 0.1968, 0.8060, 0.1558,\n",
      "         0.5756, 0.4012, 0.3151, 0.0884, 0.5884, 0.4712, 0.3407, 0.4868, 0.9094,\n",
      "         0.5851, 0.5920, 0.8784, 0.7351, 0.2111, 0.7172, 0.4161, 0.1250, 0.9599,\n",
      "         0.0120, 0.4426, 0.6650, 0.1742, 0.7052, 0.8006, 0.6800, 0.8679, 0.9277,\n",
      "         0.5333, 0.9885, 0.9109, 0.8663, 0.8132, 0.2476, 0.9309, 0.8510, 0.4701,\n",
      "         0.9568, 0.9934, 0.5899, 0.3908, 0.4365, 0.8972, 0.4873, 0.6591, 0.0675,\n",
      "         0.3869, 0.7238, 0.3497, 0.2341, 0.2386, 0.8711, 0.7346, 0.0452, 0.6458,\n",
      "         0.4614, 0.4267, 0.3245, 0.5753, 0.4257, 0.2830, 0.4076, 0.9391, 0.4388,\n",
      "         0.3198, 0.8081, 0.8953, 0.9654, 0.5029, 0.7194, 0.5733, 0.0461, 0.0756,\n",
      "         0.5989, 0.6397, 0.7828, 0.6687, 0.6642, 0.3765, 0.2411, 0.0274, 0.9745,\n",
      "         0.6491, 0.3946, 0.6930, 0.4930, 0.3933, 0.4539, 0.2009, 0.0491, 0.4851,\n",
      "         0.1281, 0.9965, 0.7744, 0.2921, 0.6869, 0.4184, 0.7564, 0.5684, 0.3076,\n",
      "         0.8652, 0.3046, 0.4570, 0.2044, 0.3368, 0.1108, 0.6699, 0.0876, 0.8043,\n",
      "         0.8016, 0.9684, 0.5217, 0.3561, 0.7589, 0.9271, 0.2356, 0.5696, 0.1331,\n",
      "         0.7785, 0.5225, 0.1412, 0.2141, 0.1206, 0.3102, 0.4699, 0.2945, 0.0577,\n",
      "         0.1302, 0.5151, 0.3706, 0.4828, 0.9533, 0.7363, 0.6050, 0.4401, 0.9677,\n",
      "         0.1326, 0.2995, 0.1164, 0.7665, 0.0672, 0.4887, 0.1630, 0.0142, 0.8890,\n",
      "         0.6649, 0.6609, 0.7695, 0.7147, 0.5041, 0.7337, 0.8639, 0.6715, 0.0607,\n",
      "         0.1918, 0.6429, 0.2605, 0.3347, 0.0351, 0.8447, 0.9917, 0.0041, 0.7569,\n",
      "         0.3633, 0.4994, 0.1857, 0.8943, 0.7592, 0.0749, 0.7822, 0.6682, 0.9725,\n",
      "         0.8349, 0.4661, 0.8920, 0.0373, 0.4521, 0.2747, 0.1694, 0.2635, 0.7111,\n",
      "         0.2876, 0.5237, 0.6401, 0.4800, 0.6520, 0.9418, 0.0039, 0.8092, 0.5412,\n",
      "         0.8929, 0.1743, 0.6869, 0.0449, 0.5504, 0.2758, 0.4346, 0.7494, 0.1039,\n",
      "         0.3368, 0.6147, 0.5261, 0.8280, 0.0197, 0.5882, 0.8476, 0.7585, 0.1913,\n",
      "         0.1888, 0.4714, 0.0685, 0.9571, 0.9798, 0.8057, 0.0033, 0.7082, 0.6965,\n",
      "         0.4084, 0.4438, 0.9430, 0.8011, 0.2456, 0.0284, 0.5231, 0.3230, 0.7272,\n",
      "         0.8537, 0.6450, 0.5011, 0.2217, 0.2024, 0.2173, 0.9186, 0.0855, 0.0726,\n",
      "         0.2074, 0.8711, 0.3973, 0.1309, 0.1906, 0.4503, 0.8417, 0.9166, 0.7949,\n",
      "         0.7328]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3635, -2.3891, -2.2601, -2.3254, -2.2731, -2.3724, -2.3198, -2.2884,\n",
       "         -2.2456, -2.2049]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.rand(28,28).view(1,-1)\n",
    "print(X)\n",
    "net_obj(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_obj = Hidden3Layer_MLP_Flattened_Image_Net(no_neurons=64,dims_img=(28,28), no_out_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3281, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3255, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1767, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0380, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2575, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "#negative log loss \n",
    "optimizer = optim.Adam(net_obj.parameters(), lr=0.01)\n",
    "Epochs = 5\n",
    "for epoch in range(Epochs):\n",
    "    for data in train:\n",
    "        X, y = data\n",
    "        net_obj.zero_grad()\n",
    "        output = net_obj(X.view(-1, 28*28))\n",
    "        loss = F.nll_loss(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9690833333333333\n"
     ]
    }
   ],
   "source": [
    "#computing accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in train:\n",
    "        X, y = data\n",
    "        output = net_obj(X.view(-1, 28*28))\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "print(\"Train Accuracy:\", correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9588\n"
     ]
    }
   ],
   "source": [
    "#computing accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test:\n",
    "        X, y = data\n",
    "        output = net_obj(X.view(-1, 28*28))\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "print(\"Test Accuracy:\", correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: tensor(4, grad_fn=<NotImplemented>)\n"
     ]
    }
   ],
   "source": [
    "for d in test:\n",
    "    print((d[0][0].size()))\n",
    "    im=d[0][0].view(28,28)\n",
    "    plt.imshow(im)\n",
    "    plt.show()\n",
    "    print(\"label:\", torch.argmax(net_obj(d[0][0].view(-1, 28*28))[0]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Design model (input, output, hidden layers, no_neurons per hidden layer, activation function.\n",
    "\n",
    "2) Construct training loop: loss function, optimizer function, learning rate, no epochs\n",
    "\n",
    "3) Train:\n",
    "   - forward pass: compute prediction (no gradient update)\n",
    "   - compute loss: (no gradients update)\n",
    "   - backward pass and update weights - update gradients - w_new = w_old + K*grad \n",
    "   - keep training till some criterion is met (Training accuracy/ dev accuracy/ no of epochs .....)\n",
    "   \n",
    "4) Compute test set accuracy - no gradient update."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
