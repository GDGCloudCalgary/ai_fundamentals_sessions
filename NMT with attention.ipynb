{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/tutorials/text/nmt_with_attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://blog.floydhub.com/attention-mechanism/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
      "2646016/2638744 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Download the file\n",
    "path_to_zip = tf.keras.utils.get_file(\n",
    "    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
    "    extract=True)\n",
    "\n",
    "path_to_file = os.path.dirname(path_to_zip)+\"/spa-eng/spa.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts the unicode file to ascii\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "      if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "\n",
    "def preprocess_sentence(w):\n",
    "    w = unicode_to_ascii(w.lower().strip())\n",
    "\n",
    "    # creating a space between a word and the punctuation following it\n",
    "    # eg: \"he is a boy.\" => \"he is a boy .\"\n",
    "    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "\n",
    "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "\n",
    "    w = w.strip()\n",
    "\n",
    "    # adding a start and an end token to the sentence\n",
    "    # so that the model know when to start and stop predicting.\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> may i borrow this book ? <end>\n",
      "b'<start> \\xc2\\xbf puedo tomar prestado este libro ? <end>'\n"
     ]
    }
   ],
   "source": [
    "en_sentence = u\"May I borrow this book?\"\n",
    "sp_sentence = u\"¿Puedo tomar prestado este libro?\"\n",
    "print(preprocess_sentence(en_sentence))\n",
    "print(preprocess_sentence(sp_sentence).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Remove the accents\n",
    "# 2. Clean the sentences\n",
    "# 3. Return word pairs in the format: [ENGLISH, SPANISH]\n",
    "def create_dataset(path, num_examples):\n",
    "    lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
    "  \n",
    "    word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
    "  \n",
    "    return zip(*word_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> if you want to sound like a native speaker , you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo . <end>\n",
      "<start> si quieres sonar como un hablante nativo , debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un musico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado . <end>\n"
     ]
    }
   ],
   "source": [
    "en, sp = create_dataset(path_to_file, None)\n",
    "print(en[-1])\n",
    "print(sp[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(lang):\n",
    "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "        filters='')\n",
    "    lang_tokenizer.fit_on_texts(lang)\n",
    "  \n",
    "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "  \n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
    "                                                           padding='post')\n",
    "  \n",
    "    return tensor, lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path, num_examples=None):\n",
    "    # creating cleaned input, output pairs\n",
    "    targ_lang, inp_lang = create_dataset(path, num_examples)\n",
    "  \n",
    "    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
    "    target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
    "  \n",
    "    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try experimenting with the size of that dataset\n",
    "num_examples = 30000\n",
    "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n",
    "\n",
    "# Calculate max_length of the target tensors\n",
    "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24000 24000 6000 6000\n"
     ]
    }
   ],
   "source": [
    "# Creating training and validation sets using an 80-20 split\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    "\n",
    "# Show length\n",
    "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(lang, tensor):\n",
    "    for t in tensor:\n",
    "        if t!=0:\n",
    "            print (\"%d ----> %s\" % (t, lang.index_word[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Language; index to word mapping\n",
      "1 ----> <start>\n",
      "17 ----> se\n",
      "1719 ----> robaron\n",
      "19 ----> mi\n",
      "357 ----> bicicleta\n",
      "3 ----> .\n",
      "2 ----> <end>\n",
      "\n",
      "Target Language; index to word mapping\n",
      "1 ----> <start>\n",
      "21 ----> my\n",
      "470 ----> bicycle\n",
      "26 ----> was\n",
      "1418 ----> stolen\n",
      "3 ----> .\n",
      "2 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "print (\"Input Language; index to word mapping\")\n",
    "convert(inp_lang, input_tensor_train[0])\n",
    "print ()\n",
    "print (\"Target Language; index to word mapping\")\n",
    "convert(targ_lang, target_tensor_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang.word_index)+1\n",
    "vocab_tar_size = len(targ_lang.word_index)+1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 16]), TensorShape([64, 11]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                     return_state=True,\n",
    "                                     recurrent_initializer='glorot_uniform')\n",
    "  \n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state = hidden)\n",
    "        return output, state\n",
    "  \n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (64, 16, 1024)\n",
      "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "# sample input\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        # query hidden state shape == (batch_size, hidden size)\n",
    "        # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # values shape == (batch_size, max_len, hidden size)\n",
    "        # we are doing this to broadcast addition along the time axis to calculate the score\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(query_with_time_axis) + self.W2(values)))\n",
    "\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (64, 1024)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (64, 16, 1)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "  \n",
    "        # used for attention\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, hidden, enc_output):\n",
    "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "  \n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "  \n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "  \n",
    "        # passing the concatenated vector to the GRU\n",
    "        output, state = self.gru(x)\n",
    "  \n",
    "        # output shape == (batch_size * 1, hidden_size)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "  \n",
    "        # output shape == (batch_size, vocab)\n",
    "        x = self.fc(output)\n",
    "  \n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (64, 4935)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                      sample_hidden, sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "  \n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "  \n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "  \n",
    "        dec_hidden = enc_hidden\n",
    "  \n",
    "        dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "  \n",
    "        # Teacher forcing - feeding the target as the next input\n",
    "        for t in range(1, targ.shape[1]):\n",
    "          # passing enc_output to the decoder\n",
    "          predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "  \n",
    "          loss += loss_function(targ[:, t], predictions)\n",
    "  \n",
    "          # using teacher forcing\n",
    "          dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 4.6751\n",
      "Epoch 1 Batch 100 Loss 2.2923\n",
      "Epoch 1 Batch 200 Loss 1.7899\n",
      "Epoch 1 Batch 300 Loss 1.7507\n",
      "Epoch 1 Loss 2.0188\n",
      "Time taken for 1 epoch 434.99446177482605 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 1.5541\n",
      "Epoch 2 Batch 100 Loss 1.5136\n",
      "Epoch 2 Batch 200 Loss 1.3175\n",
      "Epoch 2 Batch 300 Loss 1.2827\n",
      "Epoch 2 Loss 1.3625\n",
      "Time taken for 1 epoch 445.1248209476471 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 1.0934\n",
      "Epoch 3 Batch 100 Loss 0.8931\n",
      "Epoch 3 Batch 200 Loss 0.8923\n",
      "Epoch 3 Batch 300 Loss 0.8128\n",
      "Epoch 3 Loss 0.9344\n",
      "Time taken for 1 epoch 434.64963579177856 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.6263\n",
      "Epoch 4 Batch 100 Loss 0.6131\n",
      "Epoch 4 Batch 200 Loss 0.5683\n",
      "Epoch 4 Batch 300 Loss 0.5403\n",
      "Epoch 4 Loss 0.6210\n",
      "Time taken for 1 epoch 438.9706609249115 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.3982\n",
      "Epoch 5 Batch 100 Loss 0.4683\n",
      "Epoch 5 Batch 200 Loss 0.4129\n",
      "Epoch 5 Batch 300 Loss 0.4231\n",
      "Epoch 5 Loss 0.4129\n",
      "Time taken for 1 epoch 435.6649343967438 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.2305\n",
      "Epoch 6 Batch 100 Loss 0.2871\n",
      "Epoch 6 Batch 200 Loss 0.2457\n",
      "Epoch 6 Batch 300 Loss 0.2998\n",
      "Epoch 6 Loss 0.2805\n",
      "Time taken for 1 epoch 438.58085656166077 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.2049\n",
      "Epoch 7 Batch 100 Loss 0.1441\n",
      "Epoch 7 Batch 200 Loss 0.1591\n",
      "Epoch 7 Batch 300 Loss 0.1571\n",
      "Epoch 7 Loss 0.1979\n",
      "Time taken for 1 epoch 431.64479660987854 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.1158\n",
      "Epoch 8 Batch 100 Loss 0.1440\n",
      "Epoch 8 Batch 200 Loss 0.1601\n",
      "Epoch 8 Batch 300 Loss 0.1721\n",
      "Epoch 8 Loss 0.1482\n",
      "Time taken for 1 epoch 436.1450448036194 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.1248\n",
      "Epoch 9 Batch 100 Loss 0.0937\n",
      "Epoch 9 Batch 200 Loss 0.1273\n",
      "Epoch 9 Batch 300 Loss 0.1617\n",
      "Epoch 9 Loss 0.1136\n",
      "Time taken for 1 epoch 429.0752410888672 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.0732\n",
      "Epoch 10 Batch 100 Loss 0.0768\n",
      "Epoch 10 Batch 200 Loss 0.0944\n",
      "Epoch 10 Batch 300 Loss 0.1009\n",
      "Epoch 10 Loss 0.0941\n",
      "Time taken for 1 epoch 438.6798722743988 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "  \n",
    "        if batch % 100 == 0:\n",
    "          print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                     batch,\n",
    "                                                     batch_loss.numpy()))\n",
    "    # saving (checkpoint) the model every 2 epochs\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                        total_loss / steps_per_epoch))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                           maxlen=max_length_inp,\n",
    "                                                           padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "    result = ''\n",
    "\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                             dec_hidden,\n",
    "                                                             enc_out)\n",
    "\n",
    "        # storing the attention weights to plot later on\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        result += targ_lang.index_word[predicted_id] + ' '\n",
    "\n",
    "        if targ_lang.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention_plot\n",
    "\n",
    "        # the predicted ID is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for plotting the attention weights\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "  \n",
    "    fontdict = {'fontsize': 14}\n",
    "  \n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "  \n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "  \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "    result, sentence, attention_plot = evaluate(sentence)\n",
    "\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "\n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x2a74db96308>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restoring the latest checkpoint in checkpoint_dir\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> hace mucho frio aqui . <end>\n",
      "Predicted translation: it s very cold here . <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(u'hace mucho frio aqui.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> trata de averiguarlo . <end>\n",
      "Predicted translation: try to figure it out . <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd4AAAKICAYAAADeoZu0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deZRldXXo8e+mu2nCIAZQ0hiZx+CEtChRQTRqgJjBuHySREUSWyNEXEbjE5MnahCUxkQfasABgkNwiC4MEOME4oDyWsBIQAEVDUIzKAINgW6b/f44p+DWpXqke/9OVX0/a9XqqnNv3dp1F9xvnXPPEJmJJEmqsUnrASRJmk0MryRJhQyvJEmFDK8kSYUMryRJhQyvJEmFDK8kSYUMryRJhea2HkCS1lZEbAbsDiTww8y8p/FI0jpzjVfS4EXE3Ig4GbgN+C7wPeC2iHhnRMxrO520blzjlTQdvBM4Angl8PV+2dOBE+lWIF7XaC5pnYXnapY0dBGxFDgqM88fW3448MHMXNBmMmndualZ0nSwNfDDKZb/EHh48SzSQ2J4JU0H3wVePcXyY4HLi2eRHhI3NUsavIg4CDgfuAG4mG6v5gOBHYBDM/Prq/l2aVAMr6RpISJ2AI4G9gYCuBJ4X2be0HQwaR0ZXkmSCnk4kaRBiognru19M/PSjTmLtCG5xitpkCLiPrr3cmMNd83MnFMwkrRBuMYraah2aT2AtDG4xitp0PpTQp4AvDczf9J6HumhMrySBi8ilgGPyczrWs8iPVSeQEPSdPAfwDNbDyFtCL7HK2k6+DLw9oh4HPAd4K7RGzPzM02mktaDm5olDV6/h/OquFezphXDK0lSId/jlSSpkO/xSpoWImIb4HeBHYFNR2/LzLc2GUpaD25qljR4EfEU4DzgXuARwM+ABf3X12Xm4xqOJ60TNzVLmg5OBj4GPAq4h+7Qoh2BJcA7Gs4lrTPXeCUNXkTcDjwpM6+OiF8CB2bmVRHxJODjmblH4xGlteYar6TpYPnI5zcBO/WfLwN2qB9HWn/uXCVpOrgUeBJwNXAh8PcRsT3wZ8B/NpxLWmduapY0eBGxENgqMy+IiEcAZwFPpQvxyzLze00HlNaB4R2AiNgDOA041hcQSZrZfI93GF4KPAM4qvEckqSNzDXexiIigOuALwLPA3bIzJVNh5IGJiK+B6zyxcrjeDWduHNVe4cAWwGvBg4FDgP+relE0vB8euzrecAT6N7nfW/9ONL6c423sYg4E1iemYsiYjGwc2a+oPFY0rQQEa8HdsrMY1rPIq0tw9tQRGwB3Agcnplfi4gnABfTbW6+re100vBFxG7Aksz89dazSGvLnava+mPg1sz8GkBmXg5cA7yo6VTS9HEQcHfrITQMEbFFRLwkIrZuPcvq+B5vWy8GPjq27KN0ezm/v34caZgi4nPji+gukrAf8Jb6iTRQLwQ+CBwLnNp4llVyU3MjEfFo4MfAPpl5zcjy36Tby/m3MvPqRuNJgxIRZ4wtug+4BfhKZn6hwUgaoIi4EHgkcHdmLmw8zioZXknStBcRO9OdyewA4FvAEzPzypYzrYrv8TYUETv2x/FOeVv1PJI0jb0Y+Fq/r8z5dG/ZDZJrvA1FxEpgQWbePLZ8W+DmzJzTZjJpWCLix0x9Ao2kuz7vtcCHMnP8vWDNEhFxDXBCZp4ZEc8H3gM8OgcYOdd42wqmfjHZku7FRFLnDGAbur3+P9p/XNMv+xywEvhMRHhEwCwUEb9Nt7Pdp/pF5wKbA7/TbKjVcK/mBiLiPf2nCZwYEaOHQ8yhe4/i8vLBpOHaFTgpM08aXRgRf0O3I+LzI+I44A3A2S0GVFMvBc7JzLsAMnN5RHwSOJLudLyD4qbmBiLigv7Tg+lOmDF6ke/ldHs1Lx7d21mazSLiDrqdZa4dW747cGlmPiwi9gK+k5lbNhlSTUTEfGApcERmfn5k+dOA/wC2z8xlreabimu8DWTmIf1OVZ8EjsrMO1vPJA3c3cDT6d7LHfV0HjiBxhzgfyqH0iBsRXfc7qTDyjLz6xHxCrq37gYVXtd4G4mIOXTv4z5+qLu8S0MREW8E/g/wYeD/0b1NcwDdpsS3ZeZJEfFa4NDMfHazQaW1YHgbiohrgRf0u79LWo1+x6lXA3v3i74PvDszP9Hf/mtAZqY7JmrQDG9DEfFS4AjgzzLz1tbzSNJ0sZpDzB4kM3fdyOOsE9/jbet1wC7AzyLieuCu0Ru9uLckrdLouZi3BF4LXEK3wyrAgXRvR5xSPNcaGd62xi/uLanX78m8a2beGhF3spq1m8x8WN1kGoLMvD+o/XXN35GZbx+9T79vwL7Fo62Rm5o1CBFxCN1m9x2BTUdvy8xnNhlKTfVvxZydmff2n69SZv5z0VgaoLU53KzNZFNzjVfNRcSRwD8BnwWeAZwD7Em3GX78somaJSZiGhFz6a5E9O3M/HnbqTRQd9G9dowfbvYMBni9ZsPbUERsCryJB9b05o3ePovO1fw64JjM/GC/SfGNmfmjiDiVgR1/p3qZ+auI+Azd3syGV1P5B+C9EbGQ7spEAE+hO6PV8a2GWhXP1dzW2+j+wziF7vqirwfeS/fi8qqGc1XbFfhS//m9dDtKQLfzxJEtBtLgfBfYvfUQGqbMfCfd1YkeC7yr/3gs8NLMfEfL2abiGm9bLwRemZmfj4jFdOca/WFEXAU8Gzit7Xhlfk539hmAnwGPAf4T2Bb4tVZDaVCOB06JiDcD3+HBRwD8osVQGo7M/CTd2QAHz/C2tT0wcdaqZcDD+88/Dwzur7SN6GvAc4Dv0f2P856IeDbwLAZ4gnM1cV7/72eYvHfzxBW+ZsvbMlqDiHg4Y1tzh/aHmeFt66fADv2/1wLPpftr/kBm1zlnjwE26z8/EfgV8FS6CP99q6E0KIe0HkDDFRE70e2geQiT95UZ5B9mHk7UUEScCCzLzBMi4gXAvwDXA48CTs7MNzUdUJKmgYj4Ct0Ww8XADYwd852ZX20x16oY3gGJiCfTreldnZnntp6nSkSsBBZk5s1jy7cFbp5Fe3drNSLiscArgN3orup1Y0T8IfCTzLys7XRqKSKWAU/JzCtaz7I23Ku5oYg4qD9GEYDM/HZmvgv4fEQc1HC0arGK5fOZfK1izVIR8Ry6qxI9CngmD+x0txvw5lZzaTB+TPd6MS34Hm9bFwALgJvHlm/d3zaj1/T6y7hBt1nolf1frRPm0F1r9fvlg2mI3ga8NjPf1x/rPeFC4K/bjKQBORY4MSJeNX72qiEyvG1NvPE/blvGDpeYof6q/zeAvwBWjty2HLgOeGXxTBqmfYHzp1j+C2Cb4lk0POfQrfH+ICLupdtB836eMlJExOf6TxP4aP8fyoQ5dMexfrN8sGKZuQtARFwAPD8zb2s8kobrNrrNzNeNLX8i3Q6Jmt2OaT3AujC8bUyc9i7oXlBGDx1aDnwd+ED1UK1kpoeKaE0+DpwcES+k+4N1bkQcTLcX6xlNJ1Nz0+0iGe7V3FB/Fp7FmTkbNiuvVkTsCbyAqa9OdFSToTQYETEPOBN4Ed0frPf1/34cODIzV676uzUbRMT2dKeN3A34u/5ykk8FbsjMH7edbjLD21BEbAKQmff1X/8G8HvAlZk54zc1T4iIw4F/BS4D9qfbe3U3uvdsvpaZv99wPA1IROwG7Ed3RMZlmXlN45E0ABGxP/Blur2b9wX27i+0cjywZ2b+Scv5xnk4UVvn0e9gFBFbAkuAk4GvRsRLWg5W7K3AWzLzQLqLJLwY2JnuwgkXthurrYh4bEScGhH/HhEL+mV/GBH7tZ6tWkT8QUTMzcwfZuanM/OTRlcjFgPvzsz96F5DJvwH3bkRBsXwtrU/8JX+8+cDdwCPBF5Od6m82WIv4BP95yuAzTPzHrogv6bZVA153OqD/AuwNCLeHxG/3XoYDc7+wFTv895Id078QTG8bW0F/LL//DnAZzNzBV2Md2s2Vb07eeBczTfywOXf5gK/3mSi9iaOW/0jJp9E5ELggCYTtbU93WUzdwcuiogfRcTbImKvxnNpGP6HqV8r9ubB50lozvC29VPgqRGxBd0FEiauxLMNcHezqep9G3ha//l5PHD5tzOAi5tN1ZbHrY7IzDsz84zMfDbwaLprNR8KXBkRl7SdTgNwDvDmiJg4e1VGxM50V3n711ZDrYrhbetdwEfojkP8GXBRv/wgukvkzRavBb7Vf3488AXgj+mu2PQXjWZqbeK41XGz/rjVzLyRLrwn0l23ef+2E2kAXkf3B+ktwOZ0h2ReC9wO/G3DuabkXs2N9Xvj7Qh8MTOX9csOB36Zmd9oOlyB/lzVzwG+nZk/X9P9Z4uIeAfdKTNfSHfN5oV0pxc9EzgjM9/abrp2IuIQ4E/p/jAD+Czwkcy8oN1UGoqIeCbdH6ebAJdm5pcajzQlw9tIRGwNPC4zvzbFbU+lO6RoVpzJKSLuodv9/7rWswzFKo5b3QT4GLPwuNWIOJnuuXgk3Z6qHwXOycx7V/uNmvGm42up4W0kIrai25HouaNrthHxBLr3PB+Vmbe2mq9SRHwbeNNQ/zptKSJ25YG/4GftcasR8U262J6dmb9oPY+GYzq+lhrehiLiY8CyzHzFyLLFdAd8z5qTRkTEocBJdIfJfIexC0TMlhfaiPjw2t53Np7Nq39b4gCmPrvZWU2G0iBMt9dSw9tQRDyX7vjE7TNzRX8mq+uBYzLzM22nqxMR9418OfofZACZmTP68ogTIuLfxhYdRLeJeWJHu8fQrfleNMQXk42pP2zo34Bd6f67WEl3uNkK4N6hXX1Gtabba6kXSWjri3SHDT0P+AzwLLq/5MdfgGe6lwH/zeTLAkIXmR3rx2kjM5838XlEvJHu2MSXTZzLuz/s7EPMrj3eJ7wbuJTudJFLgSfQXbf6/Qxwr1WVm1avpa7xNtbvvbpXZv5hRJwF3JmZR7eeq1JErAQWZObNY8u3BW6eLWu8oyLiRuBZmXnl2PJ9gS9n5m+0mayNiPg5cHBmXhERtwMHZOYP+isU/d/MfFzjEdXYdHotdY23vbOA70TEo4E/ovtLbbYJJm9inrAlcE/xLEOxJbAD3aFEoxbQHac42wQPnFTmFrpjnH9Atzlx91V9k2aVafNaangby8z/iojv0V3e7PrMnDVn4YmI9/SfJnBiRIyerWsO3Y40l5cPNgz/CpwREa/ngZOLPIXuTDyDe8+qwBXA44EfAZcAb+i3lLyc7kQJmuWm02up4R2GjwD/CLyp9SDFHtv/G8A+TD4n8XK69/QWVw81EH8JnEJ3LO+8ftmv6N7jnU0X0JhwArBF//nfAucCFwC30p1kREBEXAXskZmz9bV9WryW+h7vAETENnSXBzwtM5e2nqdaRJwBHJuZd7SeZWj6Hap2o/vj5NqJHa10//83t6UvYveLiGOAbTPzLa1naWG6vJYaXkmSCnmRBEmSChleSZIKGd6BiIhFrWcYEp+PyXw+JvP5mMznY7KhPx+GdzgG/R9KAz4fk/l8TObzMZnPx2SDfj4MryRJhWb9Xs2bxvzc7P7DA9tZwb3MY37rMQbD52Myn4/JfD4m8/mYbCjPx53cdmtmPmJ8+Ww9yPp+m7EFT47BnllMkjRNfSk//ZOplrupWZKkQoZXkqRChleSpEKGV5KkQoZXkqRChleSpEKGV5KkQoZXkqRChleSpEKGV5KkQoZXkqRChleSpEKGV5KkQoZXkqRChleSpEKGV5KkQoZXkqRChleSpEKGV5KkQoZXkqRChleSpEKGV5KkQoZXkqRChleSpEKGV5KkQoZXkqRChleSpEKGV5KkQoMOb0RcGBGntp5DkqQNZdDhXRsRMa/1DJIkra3BhjcizgQOBo6OiOw/juz/PSwiLomI5cArImJlRCwc+/6XR8StEbFpi/klSZrK3NYDrMaxwJ7A94Hj+mX79v++A/hr4FrgTuB5wFHAkpHvPwr4SGYuL5lWkqS1MNg13sy8HVgO3J2ZSzNzKbCyv/n4zPxCZv4oM28BPgAcERGbAUTEPsBTgA9N9dgRsSgilkTEkhXcu/F/GUmSeoMN7xosGfv6HLpIP7//+ijgksy8YqpvzszTM3NhZi6cx/yNOKYkSZNN1/DeNfpFZq4AzgKOioi5wItZxdquJEktDfk9XujWYues5X0/AFwFvArYCjh7Yw0lSdL6Gnp4rwMOiIidgWWsZg09M6+OiK8DJwNnZ+YdFQNKkrQuhr6peTHdWu+VwC3Ajmu4/4eATXEzsyRpoAa9xpuZVwMHji0+czXfsgC4JjMv2mhDSZL0EAw6vGsrIrYE9qY79veExuNIkrRKQ9/UvLZOBb7Rf5zWeBZJklZpRqzxZuaRwJGNx5AkaY1myhqvJEnTguGVJKmQ4ZUkqZDhlSSpkOGVJKmQ4ZUkqZDhlSSpkOGVJKmQ4ZUkqZDhlSSpkOGVJKmQ4ZUkqZDhlSSpkOGVJKmQ4ZUkqZDhlSSpkOGVJKmQ4ZUkqZDhlSSpkOGVJKmQ4ZUkqZDhlSSpkOGVJKnQ3NYDDMImc1pPMBhXv/+JrUcYlL3+6e7WIwzKTw/fuvUIg7LTuy5vPcKg3He3/7+sDdd4JUkqZHglSSpkeCVJKmR4JUkqZHglSSpkeCVJKmR4JUkqZHglSSpkeCVJKmR4JUkqZHglSSpkeCVJKmR4JUkqZHglSSpkeCVJKmR4JUkqZHglSSpkeCVJKmR4JUkqZHglSSpkeCVJKmR4JUkqZHglSSpkeCVJKmR4JUkqZHglSSpkeCVJKmR4JUkqZHglSSpkeCVJKjTtwhsRF0bEqa3nkCRpfUy78EqSNJ1Nq/BGxJnAwcDREZH9x84RcVBEfDsi7omImyLiHyJi08bjSpL0INMqvMCxwMXAGcCC/mMF8O/AZcB+wJ8DRwAnNppRkqRVmlbhzczbgeXA3Zm5NDOXAq8CbgRelZlXZea5wP8GjomIzad6nIhYFBFLImLJCu4tm1+SpGkV3lXYB7g4M+8bWfZ1YFNg96m+ITNPz8yFmblwHvMrZpQkCZgZ4Q0gV3HbqpZLktTEdAzvcmDOyNdXAgdGxOjv8rT+fj+sHEySpDWZjuG9Djig35t5O+B9wA7A+yJin4g4HDgJODUz7244pyRJDzIdw7uYbm32SuAWYB5wKN0ezZcDHwb+BTiu1YCSJK3K3NYDrKvMvBo4cGzxdcCT66eRJGndTMc1XkmSpi3DK0lSIcMrSVIhwytJUiHDK0lSIcMrSVIhwytJUiHDK0lSIcMrSVIhwytJUiHDK0lSIcMrSVIhwytJUiHDK0lSIcMrSVIhwytJUiHDK0lSIcMrSVIhwytJUiHDK0lSIcMrSVIhwytJUiHDK0lSIcMrSVIhwytJUiHDK0lSobmtB9Cw7HX0Za1HGJb99mk9waCs/LVsPcKgXH3C41qPMCh7vH5J6xGGZcXUi13jlSSpkOGVJKmQ4ZUkqZDhlSSpkOGVJKmQ4ZUkqZDhlSSpkOGVJKmQ4ZUkqZDhlSSpkOGVJKmQ4ZUkqZDhlSSpkOGVJKmQ4ZUkqZDhlSSpkOGVJKmQ4ZUkqZDhlSSpkOGVJKmQ4ZUkqZDhlSSpkOGVJKmQ4ZUkqZDhlSSpkOGVJKmQ4ZUkqZDhlSSpkOGVJKnQBglvRGwSEadFxM8jIiPiuog4d0M8tiRJM8ncDfQ4hwEvA54B/Aj4HyA20GNLkjRjbKjw7g7cmJnf3ECPt1YiYtPMXF75MyVJeige8qbmiDgT+Adgx5HNzGeObmqOiC0i4qyIWBYRN0XEGyPi3P57J+5zXUS8buyxL4yIU8fuc3xEfDgifgl8rF/+qIg4OyJu6z/Oi4g9HurvJknShrYh3uM9FngrcD2wAHjSFPc5BTgY+CPgmcDjgaev5897LfB9YCFwXERsDlwA3NP/jAOBG4Ev9bdJkjQYD3lTc2beHhF3AiszcylAxANv70bElsBRwEsy84v9sj+nC/X6+GpmvnPk8Y+iez/5ZZmZ/bJXADcDvwd8cvwBImIRsAhgM2yzJKnOhnqPd3V2A+YBl0wsyMy7IuKK9Xy8JWNf7w/sAtw5Gnxg8/5nP0hmng6cDvCw2CbXcw5JktZZRXgnarimwN3Hg/eEnjfF/e4a+3oT4HLgRVPc9xdrnE6SpEIVJ9C4FlgBHDCxoH/v9TFj97uF7j3iiftsBuy9Fo9/Kd1e1bdm5rVjH4ZXkjQoGz28mbkM+DDwjoh4VkT8FvDB/mePrgV/BfjTiHhGROzbf89Ua7zjPgbcBJwTEQdHxC4RcVBEnOKezZKkoanY1AzwOmAL4HPAMrrDj7an2xN5wonAzsA5/X1OAHZY0wNn5t0RcRBwEvApYGvgBro9nW/bYL+BJEkbwAYJb2YuBhaPfH3k2O3LgBf3H0TEfOA1wPkj97kDOGLsod839jg7r+Ln30R35ixJkgatZI03IvYD9qHbs3kr4A39v5+o+PmSJA1F1aZm6E58sRfwK7q9kA/KzPU9lleSpGmpJLyZeRndmaYkSZrVvB6vJEmFDK8kSYUMryRJhQyvJEmFDK8kSYUMryRJhQyvJEmFDK8kSYUMryRJhQyvJEmFDK8kSYUMryRJhQyvJEmFDK8kSYUMryRJhQyvJEmFDK8kSYUMryRJhQyvJEmFDK8kSYUMryRJhQyvJEmFDK8kSYXmth5gEO5b2XqCwcj7Wk8wLHHZVa1HGJTdlu3SeoRBOf/Ln2o9wqAc+santB5hWFZMvdg1XkmSChleSZIKGV5JkgoZXkmSChleSZIKGV5JkgoZXkmSChleSZIKGV5JkgoZXkmSChleSZIKGV5JkgoZXkmSChleSZIKGV5JkgoZXkmSChleSZIKGV5JkgoZXkmSChleSZIKGV5JkgoZXkmSChleSZIKGV5JkgoZXkmSChleSZIKGV5JkgoZXkmSChleSZIKzYjwRsSZEXFu6zkkSVqTua0H2ECOBQIgIi4ErsjMY5pOJEnSFGZEeDPz9tYzSJK0NmZEeCPiTGA74FbgYODgiDi6v3mXzLyu0WiSJE0yI8I74lhgT+D7wHH9slvajSNJ0mQzKryZeXtELAfuzsylq7pfRCwCFgFsxuZV40mSNDP2al5XmXl6Zi7MzIXzmN96HEnSLDIrwytJUiszMbzLgTmth5AkaSozMbzXAQdExM4RsV1EzMTfUZI0Tc3EKC2mW+u9km6P5h3bjiNJ0gNmxF7NmXnkyOdXAwe2m0aSpFWbiWu8kiQNluGVJKmQ4ZUkqZDhlSSpkOGVJKmQ4ZUkqZDhlSSpkOGVJKmQ4ZUkqZDhlSSpkOGVJKmQ4ZUkqZDhlSSpkOGVJKmQ4ZUkqZDhlSSpkOGVJKmQ4ZUkqZDhlSSpkOGVJKmQ4ZUkqZDhlSSpkOGVJKmQ4ZUkqZDhlSSpkOGVJKnQ3NYDaGAiWk8wKDHX/0UmufWXrScYlOt/taz1CIOyyYLtW48wLD+aerFrvJIkFTK8kiQVMrySJBUyvJIkFTK8kiQVMrySJBUyvJIkFTK8kiQVMrySJBUyvJIkFTK8kiQVMrySJBUyvJIkFTK8kiQVMrySJBUyvJIkFTK8kiQVMrySJBUyvJIkFTK8kiQVMrySJBUyvJIkFTK8kiQVMrySJBUyvJIkFTK8kiQVMrySJBUyvJIkFTK8kiQVmnHhjYhnRERGxHatZ5EkadyMC68kSUM2uPBGxPyI+MeIuCki7omIb0XE0/rbHrQ2GxE798sWRsTOwAX9Tbf0y88s/yUkSVqFwYUXeCfwv4CjgP2A7wGfj4gFa/G9/w38cf/5vsAC4NiNMaQkSetjUOGNiC2AvwTekJnnZeZVwCuBm4Cj1/T9mbkS+EX/5c2ZuTQzb5/i5yyKiCURsWQF927A30CSpNUbVHiB3YB5wDcmFvQxvRj4rQ31QzLz9MxcmJkL5zF/Qz2sJElrNLTwRv9vTnFbAveN3Q+6UEuSNC0MLbzXAsuBp00siIg5wIHAlcAt/eLR93ufMPYYy/t/52ykGSVJWm+DCm9m3gW8HzgpIg6LiH36r7cH3kcX5v8Gjo+IPSPiOcDfjj3MT+jWjg+PiEdExJZ1v4EkSas3qPD23gB8EjgDuBx4HPC7mXljZq4AXgTsCnwXeAtw3Og3Z+bPgDcDJ9DtlHVq3eiSJK3e3NYDjMvMe4HX9B9T3f5NHrx5Ocbu8zbgbRtlQEmSHoIhrvFKkjRjGV5JkgoZXkmSChleSZIKGV5JkgoZXkmSChleSZIKGV5JkgoZXkmSChleSZIKGV5JkgoZXkmSChleSZIKGV5JkgoZXkmSChleSZIKGV5JkgoZXkmSChleSZIKGV5JkgoZXkmSChleSZIKGV5JkgoZXkmSChleSZIKGV5JkgoZXkmSCs1tPYAGJrP1BINy3z33tB5hWHw+JvmD7x7VeoRBWfYX27YeYViOm3qxa7ySJBUyvJIkFTK8kiQVMrySJBUyvJIkFTK8kiQVMrySJBUyvJIkFTK8kiQVMrySJBUyvJIkFTK8kiQVMrySJBUyvJIkFTK8kiQVMrySJBUyvJIkFTK8kiQVMrySJBUyvJIkFTK8kiQVMrySJBUyvJIkFTK8kiQVMrySJBUyvJIkFTK8kiQVMrySJBUyvJIkFTK8kiQVMrySJBUyvJIkFTK8kiQVmtt6gBYiYhGwCGAzNm88jSRpNpmVa7yZeXpmLszMhfOY33ocSdIsMivDK0lSK4ZXkqRCMza8EXFMRHy/9RySJI2aseEFtgP2aj2EJEmjZmx4M/P4zIzWc0iSNGrGhleSpCEyvJIkFTK8kiQVMrySJBUyvJIkFTK8kiQVMrySJBUyvJIkFTK8kiQVMrySJBUyvJIkFTK8kiQVMrySJBUyvJIkFTK8kiQVMrySJBUyvJIkFTK8kiQVMrySJBUyvJIkFTK8kiQVMrySJBUyvJIkFTK8kiQVMrySJBUyvJIkFTK8kiQVmtt6AEmaru65eLvWIwzK8p1WtB5hWnCNV5KkQoZXkqRChleSpEKGV5KkQoZXkqRChleSpEKGV5KkQoZXkqRChleSpEKGV5KkQoZXkqRChleSpEKGV5KkQoZXkqRChleSpEKGV5KkQoZXksDAxpIAAAXWSURBVKRChleSpEKGV5KkQoZXkqRChleSpEKGV5KkQoZXkqRChleSpEKGV5KkQoZXkqRChleSpEKGV5KkQtMmvBHxuoi4rvUckiQ9FNMmvJIkzQQbJLwR8bCIePiGeKx1+JmPiIjNKn+mJEkP1XqHNyLmRMRzI+LjwFLg8f3yrSPi9Ii4OSLujIivRsTCke87MiKWRcSzIuKKiLgrIi6IiF3GHv9vImJpf9+zgC3HRjgMWNr/rKeu7+8hSVKldQ5vROwbEe8Efgp8ArgL+F3googI4DzgUcDvAfsBFwFfiYgFIw8zH3gjcBRwIPBw4J9GfsYLgb8H3gw8EfgB8NqxUT4G/AmwFfDFiLg2Iv7PeMAlSRqStQpvRGwbEa+OiCXAZcDewGuA7TPz5Zl5UWYmcAjwBOAFmXlJZl6bmX8H/Ah48chDzgWO7u/zn8Bi4JCImJjnNcA/Z+ZpmXl1Zp4AXDI6U2b+KjPPz8wjgO2Bt/c//5p+LfuoiBhfS574fRZFxJKIWLKCe9fmKZAkaYNY2zXevwLeDdwL7JGZv5+Zn8rM8WrtD2wO3NJvIl4WEcuAxwC7jdzv3sz8wcjXNwDz6NZ8AfYBLh577PGv75eZd2bmhzPzEOBJwCOBDwEvWMX9T8/MhZm5cB7zV/NrS5K0Yc1dy/udDqwAXgL8V0R8FvgI8OXMXDlyv02Am4CnT/EYd4x8/qux23Lk+9dZRMwHDqdbqz4M+C+6teZz1ufxJEnaWNYqdJl5Q2aekJl7Ab8DLAPOBq6PiFMiYr/+rpfSbfa9r9/MPPpx8zrMdRXwlLFlk76OztMi4jS6nbtOBa4F9s/MJ2bmuzPztnX4mZIkbXTrvIaZmd/KzL8EFtBtgt4TuCQing58CfgGcE5EHBoRu0TEgRHxlv72tfVu4KUR8fKI2CMi3gg8eew+fwZ8AXgYcATw6Mx8fWZesa6/kyRJVdZ2U/OD9O/vfhr4dEQ8EliZmRkRh9HtkfwBuvdab6KL8Vnr8NifiIhdgRPo3jP+HPAu4MiRu30Z+I3MvOPBjyBJ0jBFtzPy7PWw2CafHM9qPYakaej643679QiDcvdOK1qPMCg/XfSG72TmwvHlnjJSkqRChleSpEKGV5KkQoZXkqRChleSpEKGV5KkQoZXkqRChleSpEKGV5KkQoZXkqRChleSpEKGV5KkQoZXkqRChleSpEKGV5KkQoZXkqRChleSpEKGV5KkQoZXkqRChleSpEKGV5KkQoZXkqRChleSpEKGV5KkQoZXkqRChleSpEKGV5KkQnNbDyBJ09Vvvv2brUfQgP10Fctd45UkqZDhlSSpkOGVJKmQ4ZUkqZDhlSSpkOGVJKmQ4ZUkqZDhlSSpkOGVJKmQ4ZUkqZDhlSSpkOGVJKmQ4ZUkqZDhlSSpkOGVJKmQ4ZUkqZDhlSSpkOGVJKmQ4ZUkqZDhlSSpkOGVJKmQ4ZUkqZDhlSSpkOGVJKmQ4ZUkqZDhlSSpkOGVJKmQ4ZUkqZDhlSSpkOGVJKmQ4ZUkqZDhlSSpkOGVJKnQ3NYDtBARi4BFAJuxeeNpJEmzyaxc483M0zNzYWYunMf81uNIkmaRWRleSZJaMbySJBUyvJIkFTK8kiQVMrySJBUyvJIkFTK8kiQVMrySJBUyvJIkFTK8kiQVMrySJBUyvJIkFTK8kiQVMrySJBUyvJIkFTK8kiQVMrySJBUyvJIkFTK8kiQVMrySJBUyvJIkFTK8kiQVMrySJBUyvJIkFTK8kiQVMrySJBUyvJIkFTK8kiQVMrySJBUyvJIkFTK8kiQVMrySJBWKzGw9Q1MRcQvwk9ZzANsBt7YeYkB8Pibz+ZjM52Myn4/JhvJ87JSZjxhfOOvDOxQRsSQzF7aeYyh8Pibz+ZjM52Myn4/Jhv58uKlZkqRChleSpEKGdzhObz3AwPh8TObzMZnPx2Q+H5MN+vnwPV5Jkgq5xitJUiHDK0lSIcMrSVIhwytJUiHDK0lSof8PJ0PqVscQGT4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# wrong translation\n",
    "translate(u'trata de averiguarlo.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
